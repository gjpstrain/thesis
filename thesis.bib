@manual{allaire_2024,
  type = {Manual},
  title = {Quarto: {{R}} Interface to 'quarto' Markdown Publishing System},
  author = {Allaire, {\relax JJ} and Dervieux, Christophe},
  year = {2024}
}

@article{alter_2018,
  title = {Responsible {{Practices}} for {{Data Sharing}}},
  author = {Alter, George and Gonzalez, Richard},
  year = {2018},
  journal = {The American psychologist},
  volume = {73},
  number = {2},
  pages = {146--156},
  issn = {0003-066X},
  doi = {10.1037/amp0000258},
  urldate = {2024-10-10},
  abstract = {Research transparency, reproducibility, and data sharing uphold core principles of science at a time when the integrity of scientific research is being questioned. This paper discusses how research data in psychology can be made accessible for reproducibility and reanalysis. We describe ways to overcome barriers to data sharing, such as practical measures for protecting the confidentiality of research participants and improving documentation of the research process. We also advocate policies that recognize research data and program code as important scientific contributions.},
  pmcid = {PMC5967383},
  pmid = {29481108},
  file = {C:\Users\mbch4gs2\Zotero\storage\F5WJTP5Q\Alter and Gonzalez - 2018 - Responsible Practices for Data Sharing.pdf}
}

@article{anwyl_2020,
  title = {Gorilla in Our Midst: {{An}} Online Behavioral Experiment Builder},
  shorttitle = {Gorilla in Our Midst},
  author = {{Anwyl-Irvine}, Alexander L. and Massonni{\'e}, Jessica and Flitton, Adam and Kirkham, Natasha and Evershed, Jo K.},
  year = {2020},
  month = feb,
  journal = {Behavior Research Methods},
  volume = {52},
  number = {1},
  pages = {388--407},
  issn = {1554-3528},
  doi = {10.3758/s13428-019-01237-x},
  urldate = {2024-10-03},
  abstract = {Behavioral researchers are increasingly conducting their studies online, to gain access to large and diverse samples that would be difficult to get in a laboratory environment. However, there are technical access barriers to building experiments online, and web browsers can present problems for consistent timing---an important issue with reaction-time-sensitive measures. For example, to ensure accuracy and test--retest reliability in presentation and response recording, experimenters need a working knowledge of programming languages such as JavaScript. We review some of the previous and current tools for online behavioral research, as well as how well they address the issues of usability and timing. We then present the Gorilla Experiment Builder (gorilla.sc), a fully tooled experiment authoring and deployment platform, designed to resolve many timing issues and make reliable online experimentation open and accessible to a wider range of technical abilities. To demonstrate the platform's aptitude for accessible, reliable, and scalable research, we administered a task with a range of participant groups (primary school children and adults), settings (without supervision, at home, and under supervision, in both schools and public engagement events), equipment (participant's own computer, computer supplied by the researcher), and connection types (personal internet connection, mobile phone 3G/4G). We used a simplified flanker task taken from the attentional network task (Rueda, Posner, \& Rothbart, 2004). We replicated the ``conflict network'' effect in all these populations, demonstrating the platform's capability to run reaction-time-sensitive experiments. Unresolved limitations of running experiments online are then discussed, along with potential solutions and some future features of the platform.},
  langid = {english},
  keywords = {Artificial Intelligence,Attentional control,Browser timing,Online methods,Online research,Remote testing,Timing accuracy},
  file = {C:\Users\mbch4gs2\Zotero\storage\CI9CIJY4\Anwyl-Irvine et al. - 2020 - Gorilla in our midst An online behavioral experim.pdf}
}

@article{arechar_2018,
  title = {Conducting Interactive Experiments Online},
  author = {Arechar, Antonio A. and G{\"a}chter, Simon and Molleman, Lucas},
  year = {2018},
  month = mar,
  journal = {Experimental Economics},
  volume = {21},
  number = {1},
  pages = {99--131},
  issn = {1573-6938},
  doi = {10.1007/s10683-017-9527-2},
  urldate = {2024-10-04},
  abstract = {Online labor markets provide new opportunities for behavioral research, but conducting economic experiments online raises important methodological challenges. This particularly holds for interactive designs. In this paper, we provide a methodological discussion of the similarities and differences between interactive experiments conducted in the laboratory and online. To this end, we conduct a repeated public goods experiment with and without punishment using samples from the laboratory and the online platform Amazon Mechanical Turk. We chose to replicate this experiment because it is long and logistically complex. It therefore provides a good case study for discussing the methodological and practical challenges of online interactive experimentation. We find that basic behavioral patterns of cooperation and punishment in the laboratory are replicable online. The most important challenge of online interactive experiments is participant dropout. We discuss measures for reducing dropout and show that, for our case study, dropouts are exogenous to the experiment. We conclude that data quality for interactive experiments via the Internet is adequate and reliable, making online interactive experimentation a potentially valuable complement to laboratory studies.},
  langid = {english},
  keywords = {Amazon Mechanical Turk,Behavioral research,C71,C88,C90,D71,Experimental methodology,Internet experiments,Public goods game,Punishment},
  file = {C:\Users\mbch4gs2\Zotero\storage\JYT8JH6G\Arechar et al. - 2018 - Conducting interactive experiments online.pdf}
}

@article{ayris_2018,
  title = {{{LIBER Open Science Roadmap}}},
  author = {Ayris, Paul and Bernal, Isabel and Cavalli, Valentino and Dorch, Bertil and Frey, Jeannette and Hallik, Martin and {Hormia-Poutanen}, Kistiina and {Labastida i Juan}, Ignasi and MacColl, John and Ponsati Obiols, Agn{\`e}s and Sacchi, Simone and Scholze, Frank and Schmidt, Birgit and Smit, Anja and Sofronijevic, Adam and Stojanovski, Jadranka and Svoboda, Martin and Tsakonas, Giannis and {van Otegem}, Matthijs and Verheusen, Astrid and Vilks, Andris and Widmark, Wilhelm and Horstmann, Wolfram},
  year = {2018},
  month = jul,
  publisher = {Ligue des biblioth{\`e}ques europ{\'e}ennes de recherche},
  doi = {10.20350/digitalCSIC/15061},
  urldate = {2023-09-13},
  abstract = {Embracing Open Science is critical if we are to make science more collaborative, reproducible, transparent and impactful. Open Science undoubtedly has the power to positively influence society, but its implementation is not yet universal.},
  copyright = {openAccess},
  langid = {english},
  annotation = {Accepted: 2018-07-09T11:07:00Z}
}

@article{azzam_2013,
  title = {Data {{Visualization}} and {{Evaluation}}},
  author = {Azzam, Tarek and Evergreen, Stephanie and Germuth, Amy A. and Kistler, Susan J.},
  year = {2013},
  journal = {New Directions for Evaluation},
  volume = {2013},
  number = {139},
  pages = {7--32},
  issn = {1534-875X},
  doi = {10.1002/ev.20065},
  urldate = {2022-09-08},
  abstract = {This chapter elaborates on the definition of data visualization, highlights its historical development, and offers examples of how data visualization has been used in evaluations to help aid understanding, collect data and information, conduct analysis, and communicate to a variety of stakeholders. This chapter also outlines future trends in data visualization and their potential influence on evaluation practice. The chapter concludes with some of the main limitations and cautions that are associated with data visualization. {\copyright} Wiley Periodicals, Inc., and the American Evaluation Association.},
  langid = {english},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\7IET9HAL\\Azzam et al. - 2013 - Data Visualization and Evaluation.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\CF8CVZ8C\\ev.html}
}

@article{barr_2013,
  title = {Random Effects Structure for Confirmatory Hypothesis Testing: {{Keep}} It Maximal},
  shorttitle = {Random Effects Structure for Confirmatory Hypothesis Testing},
  author = {Barr, Dale J. and Levy, Roger and Scheepers, Christoph and Tily, Harry J.},
  year = {2013},
  month = apr,
  journal = {Journal of memory and language},
  volume = {68},
  number = {3},
  pages = {10.1016/j.jml.2012.11.001},
  issn = {0749-596X},
  doi = {10.1016/j.jml.2012.11.001},
  urldate = {2022-08-23},
  abstract = {Linear mixed-effects models (LMEMs) have become increasingly prominent in psycholinguistics and related areas. However, many researchers do not seem to appreciate how random effects structures affect the generalizability of an analysis. Here, we argue that researchers using LMEMs for confirmatory hypothesis testing should minimally adhere to the standards that have been in place for many decades. Through theoretical arguments and Monte Carlo simulation, we show that LMEMs generalize best when they include the maximal random effects structure justified by the design. The generalization performance of LMEMs including data-driven random effects structures strongly depends upon modeling criteria and sample size, yielding reasonable results on moderately-sized samples when conservative criteria are used, but with little or no power advantage over maximal models. Finally, random-intercepts-only LMEMs used on within-subjects and/or within-items data from populations where subjects and/or items vary in their sensitivity to experimental manipulations always generalize worse than separate F1 and F2 tests, and in many cases, even worse than F1 alone. Maximal LMEMs should be the `gold standard' for confirmatory hypothesis testing in psycholinguistics and beyond.},
  pmcid = {PMC3881361},
  pmid = {24403724},
  file = {C:\Users\mbch4gs2\Zotero\storage\S7MDHRLZ\Barr et al. - 2013 - Random effects structure for confirmatory hypothes.pdf}
}

@misc{bates_2018,
  title = {Parsimonious {{Mixed Models}}},
  author = {Bates, Douglas and Kliegl, Reinhold and Vasishth, Shravan and Baayen, Harald},
  year = {2018},
  journal = {arXiv.org},
  urldate = {2024-10-09},
  abstract = {The analysis of experimental data with mixed-effects models requires decisions about the specification of the appropriate random-effects structure. Recently, Barr, Levy, Scheepers, and Tily, 2013 recommended fitting `maximal' models with all possible random effect components included. Estimation of maximal models, however, may not converge. We show that failure to converge typically is not due to a suboptimal estimation algorithm, but is a consequence of attempting to fit a model that is too complex to be properly supported by the data, irrespective of whether estimation is based on maximum likelihood or on Bayesian hierarchical modeling with uninformative or weakly informative priors. Importantly, even under convergence, overparameterization may lead to uninterpretable models. We provide diagnostic tools for detecting overparameterization and guiding model simplification.},
  howpublished = {https://arxiv.org/abs/1506.04967v2},
  langid = {english},
  file = {C:\Users\mbch4gs2\Zotero\storage\3DPP68UG\Bates et al. - 2015 - Parsimonious Mixed Models.pdf}
}

@inproceedings{bertini_2004,
  title = {Quality {{Metrics}} for {{2D Scatterplot Graphics}}: {{Automatically Reducing Visual Clutter}}},
  shorttitle = {Quality {{Metrics}} for {{2D Scatterplot Graphics}}},
  booktitle = {Smart {{Graphics}}},
  author = {Bertini, Enrico and Santucci, Giuseppe},
  editor = {Butz, Andreas and Kr{\"u}ger, Antonio and Olivier, Patrick},
  year = {2004},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {77--89},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-24678-7_8},
  abstract = {The problem of visualizing huge amounts of data is very well known in the field of Computer Graphics. Visualizing large number of items (the order of millions) forces almost any kind of techniques to reveal its limits in terms of expressivity and scalability. To deal with this problem we propose a ''feature preservation'' approach, based on the idea of modelling the final visualization in a virtual space in order to analyze its features (e.g, absolute and relative density, clusters, etc.). Through this approach we provide a formal model to measure the visual clutter resulting from the representation of a large dataset on a physical device, obtaining some figures about the visualization decay and devising an automatic sampling strategy able to preserve relative densities.},
  isbn = {978-3-540-24678-7},
  langid = {english},
  keywords = {Active Pixel,Data Density,Information Visualization,Quality Metrics,Relative Density},
  file = {C:\Users\mbch4gs2\Zotero\storage\WYMBD4D7\Bertini and Santucci - 2004 - Quality Metrics for 2D Scatterplot Graphics Autom.pdf}
}

@article{bobko_1979,
  title = {The {{Perception}} of {{Pearson Product Moment Correlations}} from {{Bivariate Scatterplots}}},
  author = {Bobko, Philip and Karren, Ronald},
  year = {1979},
  journal = {Personnel Psychology},
  volume = {32},
  number = {2},
  pages = {313--325},
  issn = {1744-6570},
  doi = {10.1111/j.1744-6570.1979.tb02137.x},
  urldate = {2022-06-14},
  abstract = {Perceptions about the Pearson product moment correlation, r, from bivariate scatterplots were investigated through the use of a questionnaire. It was found that subjects who are relatively sophisticated in psychometric techniques tend to underestimate the magnitude of r, with most pronounced disparity in the range .2 {$<$} {\textbar}r{\textbar} \&lt .6. Additionally, estimates of r from specially designed scatterplots indicated that subjects (1) correctly estimated the effects of range restriction, (2) underestimated the effects of attenuating outliers, (3) incorrectly reduced estimates of r when the regression slope was relatively high or low, and (4) often failed to consider the effects of removing the middle third of the data. Several implications of these generally conservative estimations are discussed.},
  langid = {english},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\JZ5EF6NA\\Bobko and Karren - 1979 - The Perception of Pearson Product Moment Correlati.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\QWHWXG3V\\j.1744-6570.1979.tb02137.html}
}

@article{boettiger_2015,
  title = {An Introduction to {{Docker}} for Reproducible Research},
  author = {Boettiger, Carl},
  year = {2015},
  month = jan,
  journal = {SIGOPS Oper. Syst. Rev.},
  volume = {49},
  number = {1},
  pages = {71--79},
  issn = {0163-5980},
  doi = {10.1145/2723872.2723882},
  urldate = {2024-10-09},
  abstract = {As computational work becomes more and more integral to many aspects of scientific research, computational reproducibility has become an issue of increasing importance to computer systems researchers and domain scientists alike. Though computational reproducibility seems more straight forward than replicating physical experiments, the complex and rapidly changing nature of computer environments makes being able to reproduce and extend such work a serious challenge. In this paper, I explore common reasons that code developed for one research project cannot be successfully executed or extended by subsequent researchers. I review current approaches to these issues, including virtual machines and workflow systems, and their limitations. I then examine how the popular emerging technology Docker combines several areas from systems research - such as operating system virtualization, cross-platform portability, modular re-usable elements, versioning, and a 'DevOps' philosophy, to address these challenges. I illustrate this with several examples of Docker use with a focus on the R statistical environment.},
  file = {C:\Users\mbch4gs2\Zotero\storage\S24E64X2\Boettiger - 2015 - An introduction to Docker for reproducible research.pdf}
}

@article{boettiger_2017,
  title = {An {{Introduction}} to {{Rocker}}: {{Docker Containers}} for {{R}}},
  shorttitle = {An {{Introduction}} to {{Rocker}}},
  author = {Boettiger, Carl and Eddelbuettel, Dirk},
  year = {2017},
  journal = {The R Journal},
  volume = {9},
  number = {2},
  pages = {527},
  issn = {2073-4859},
  doi = {10.32614/RJ-2017-065},
  urldate = {2024-10-16},
  abstract = {We describe the Rocker project, which provides a widely-used suite of Docker images with customized R environments for particular tasks. We discuss how this suite is organized, and how these tools can increase portability, scaling, reproducibility, and convenience of R users and developers.},
  langid = {english},
  file = {C:\Users\mbch4gs2\Zotero\storage\VRSJGGFU\Boettiger and Eddelbuettel - 2017 - An Introduction to Rocker Docker Containers for R.pdf}
}

@article{bridges_2020,
  title = {The Timing Mega-Study: Comparing a Range of Experiment Generators, Both Lab-Based and Online},
  shorttitle = {The Timing Mega-Study},
  author = {Bridges, David and Pitiot, Alain and MacAskill, Michael R. and Peirce, Jonathan W.},
  year = {2020},
  month = jul,
  journal = {PeerJ},
  volume = {8},
  pages = {e9414},
  publisher = {PeerJ Inc.},
  issn = {2167-8359},
  doi = {10.7717/peerj.9414},
  urldate = {2024-10-03},
  abstract = {Many researchers in the behavioral sciences depend on research software that presents stimuli, and records response times, with sub-millisecond precision. There are a large number of software packages with which to conduct these behavioral experiments and measure response times and performance of participants. Very little information is available, however, on what timing performance they achieve in practice. Here we report a wide-ranging study looking at the precision and accuracy of visual and auditory stimulus timing and response times, measured with a Black Box Toolkit. We compared a range of popular packages: PsychoPy, E-Prime{\textregistered}, NBS Presentation{\textregistered}, Psychophysics Toolbox, OpenSesame, Expyriment, Gorilla, jsPsych, Lab.js and Testable. Where possible, the packages were tested on Windows, macOS, and Ubuntu, and in a range of browsers for the online studies, to try to identify common patterns in performance. Among the lab-based experiments, Psychtoolbox, PsychoPy, Presentation and E-Prime provided the best timing, all with mean precision under 1 millisecond across the visual, audio and response measures. OpenSesame had slightly less precision across the board, but most notably in audio stimuli and Expyriment had rather poor precision. Across operating systems, the pattern was that precision was generally very slightly better under Ubuntu than Windows, and that macOS was the worst, at least for visual stimuli, for all packages. Online studies did not deliver the same level of precision as lab-based systems, with slightly more variability in all measurements. That said, PsychoPy and Gorilla, broadly the best performers, were achieving very close to millisecond precision on several browser/operating system combinations. For response times (measured using a high-performance button box), most of the packages achieved precision at least under 10 ms in all browsers, with PsychoPy achieving a precision under 3.5 ms in all. There was considerable variability between OS/browser combinations, especially in audio-visual synchrony which is the least precise aspect of the browser-based experiments. Nonetheless, the data indicate that online methods can be suitable for a wide range of studies, with due thought about the sources of variability that result. The results, from over 110,000 trials, highlight the wide range of timing qualities that can occur even in these dedicated software packages for the task. We stress the importance of scientists making their own timing validation measurements for their own stimuli and computer configuration.},
  langid = {english},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\DTLJS2L6\\Bridges et al. - 2020 - The timing mega-study comparing a range of experi.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\IKCSU4QQ\\Bridges et al. - 2020 - The timing mega-study comparing a range of experi.pdf}
}

@article{brown_2021,
  title = {An {{Introduction}} to {{Linear Mixed-Effects Modeling}} in {{R}}},
  author = {Brown, Violet A.},
  year = {2021},
  month = jan,
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {4},
  number = {1},
  pages = {2515245920960351},
  publisher = {SAGE Publications Inc},
  issn = {2515-2459},
  doi = {10.1177/2515245920960351},
  urldate = {2024-10-08},
  abstract = {This Tutorial serves as both an approachable theoretical introduction to mixed-effects modeling and a practical introduction to how to implement mixed-effects models in R. The intended audience is researchers who have some basic statistical knowledge, but little or no experience implementing mixed-effects models in R using their own data. In an attempt to increase the accessibility of this Tutorial, I deliberately avoid using mathematical terminology beyond what a student would learn in a standard graduate-level statistics course, but I reference articles and textbooks that provide more detail for interested readers. This Tutorial includes snippets of R code throughout; the data and R script used to build the models described in the text are available via OSF at https://osf.io/v6qag/, so readers can follow along if they wish. The goal of this practical introduction is to provide researchers with the tools they need to begin implementing mixed-effects models in their own research.},
  langid = {english},
  file = {C:\Users\mbch4gs2\Zotero\storage\L39C4ZEA\Brown - 2021 - An Introduction to Linear Mixed-Effects Modeling in R.pdf}
}

@article{brysbaert_2019,
  title = {How Many Participants Do We Have to Include in Properly Powered Experiments? {{A}} Tutorial of Power Analysis with Reference Tables},
  author = {Brysbaert, Marc},
  year = {2019},
  journal = {Journal of cognition},
  volume = {2},
  number = {1},
  publisher = {Ubiquity Press}
}

@manual{buildmer,
  type = {Manual},
  title = {Buildmer: {{Stepwise}} Elimination and Term Reordering for Mixed-Effects Regression},
  author = {Voeten, Cesko C.},
  year = {2023}
}

@article{champion_2017,
  title = {Contrast Effects on Speed Perception for Linear and Radial Motion},
  author = {Champion, Rebecca A. and Warren, Paul A.},
  year = {2017},
  month = nov,
  journal = {Vision Research},
  volume = {140},
  pages = {66--72},
  issn = {1878-5646},
  doi = {10.1016/j.visres.2017.07.013},
  abstract = {Speed perception is vital for safe activity in the environment. However, considerable evidence suggests that perceived speed changes as a function of stimulus contrast, with some investigators suggesting that this might have meaningful real-world consequences (e.g. driving in fog). In the present study we investigate whether the neural effects of contrast on speed perception occur at the level of local or global motion processing. To do this we examine both speed discrimination thresholds and contrast-dependent speed perception for two global motion configurations that have matched local spatio-temporal structure. Specifically we compare linear and radial configurations, the latter of which arises very commonly due to self-movement. In experiment 1 the stimuli comprised circular grating patches. In experiment 2, to match stimuli even more closely, motion was presented in multiple local Gabor patches equidistant from central fixation. Each patch contained identical linear motion but the global configuration was either consistent with linear or radial motion. In both experiments 1 and 2, discrimination thresholds and contrast-induced speed biases were similar in linear and radial conditions. These results suggest that contrast-based speed effects occur only at the level of local motion processing, irrespective of global structure. This result is interpreted in the context of previous models of speed perception and evidence suggesting differences in perceived speed of locally matched linear and radial stimuli.},
  langid = {english},
  pmid = {28822716},
  keywords = {2D motion,Acceleration,Contrast,Contrast Sensitivity,Global motion,Humans,Local motion,Motion Perception,Psychophysics,Sensory Thresholds,Speed perception},
  file = {C:\Users\mbch4gs2\Zotero\storage\2YKDA835\Champion and Warren - 2017 - Contrast effects on speed perception for linear an.pdf}
}

@misc{chara_2021,
  title = {We Recently Went Viral on {{TikTok}} - Here's What We Learned},
  author = {Charalambides, Nick},
  year = {2021},
  month = aug,
  journal = {Prolific},
  urldate = {2024-10-04},
  howpublished = {https://www.prolific.com/resources/we-recently-went-viral-on-tiktok-heres-what-we-learned},
  langid = {english},
  file = {C:\Users\mbch4gs2\Zotero\storage\UEAFCRQ5\we-recently-went-viral-on-tiktok-heres-what-we-learned.html}
}

@article{charness_2012,
  title = {Experimental Methods: {{Between-subject}} and within-Subject Design},
  shorttitle = {Experimental Methods},
  author = {Charness, Gary and Gneezy, Uri and Kuhn, Michael A.},
  year = {2012},
  month = jan,
  journal = {Journal of Economic Behavior \& Organization},
  volume = {81},
  number = {1},
  pages = {1--8},
  issn = {0167-2681},
  doi = {10.1016/j.jebo.2011.08.009},
  urldate = {2024-10-14},
  abstract = {In this article we explore the issues that surround within-subject and between-subject designs. We describe experiments in economics and in psychology that make comparisons using either of these designs (or both) that sometimes yield the same results and sometimes do not. The overall goal is to establish a framework for understanding which critical questions need to be asked about such experimental studies, what authors of such studies can do to ameliorate fears of confoundedness, and which scenarios are particularly susceptible to divergent results from the two approaches. Overall, we find that both designs have their merits, and the choice of designs should be carefully considered in the context of the question being studied and in terms of the practical implementation of the research study.},
  keywords = {Between-subject,Experimental design and methodology,Within-subject},
  file = {C:\Users\mbch4gs2\Zotero\storage\HHYXHGRZ\S0167268111002289.html}
}

@article{cleveland_1982,
  title = {Variables on {{Scatterplots Look More Highly Correlated When}} the {{Scales Are Increased}}},
  author = {Cleveland, W. S. and Diaconis, P. and Mcgill, R.},
  year = {1982},
  month = jun,
  journal = {Science},
  volume = {216},
  number = {4550},
  pages = {1138--1141},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.216.4550.1138},
  urldate = {2021-02-08},
  abstract = {Judged association between two variables represented on scatterplots increased when the scales on the horizontal and vertical axes were simultaneously increased so that the size of the point cloud within the frame o f t h e plot decreased. Judged association was very diferent from the correlation coeficient, r, which is the most widely used measure of association.},
  langid = {english},
  file = {C:\Users\mbch4gs2\Zotero\storage\JLQ37IE5\Cleveland et al. - 1982 - Variables on Scatterplots Look More Highly Correla.pdf}
}

@article{collberg_2016,
  title = {Repeatability in Computer Systems Research},
  author = {Collberg, Christian and Proebsting, Todd A.},
  year = {2016},
  month = feb,
  journal = {Communications of the ACM},
  volume = {59},
  number = {3},
  pages = {62--69},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/2812803},
  urldate = {2024-10-09},
  abstract = {To encourage repeatable research, fund repeatability engineering and reward commitments to sharing research artifacts.},
  langid = {english}
}

@article{collyer_1990,
  title = {Psychology of the {{Scientist}}: {{LXIII}}. {{Perceiving Scattergrams}}: {{Is Visual Line Fitting Related}} to {{Estimation}} of the {{Correlation Coefficient}}?},
  shorttitle = {Psychology of the {{Scientist}}},
  author = {Collyer, Charles E. and Stanley, Kerrie A. and Bowater, Caroline},
  year = {1990},
  month = oct,
  journal = {Perceptual and Motor Skills},
  volume = {71},
  number = {2},
  pages = {371-378E},
  publisher = {SAGE Publications Inc},
  issn = {0031-5125},
  doi = {10.2466/pms.1990.71.2.371},
  urldate = {2022-09-13},
  abstract = {Visual line fitting and direct estimation of the correlation coefficient were carried out by 50 subjects using computer-generated scattergrams as stimuli. In visual line fitting, slopes of visual lines were generally greater than the corresponding regression slopes, in agreement with the hypothesis that visual lines are placed so as to bisect the cloud of displayed points at the cloud's major axis rather than to approximate a regression line. Subjects tended to underestimate the correlation coefficient, scaling their judgments of linear structure somewhat more as if they were judging the coefficient of determination. With the actual degree of linear structure partialed out, there were no strong relationships between measures of visual line fitting and measures of estimation. While both of these tasks offer quickly-obtained correlates of linear structure in scattergrams, users should be aware of their biases. We suggest that visual lines do not approximate regression lines very well and estimates of correlation do not approximate the correlation coefficient very well, because the perceptual processes involved perform operations other than regression and correlation. In the present data, these operations appeared to be independent of each other.},
  langid = {english},
  file = {C:\Users\mbch4gs2\Zotero\storage\AYL3S2D2\Collyer et al. - 1990 - Psychology of the Scientist LXIII. Perceiving Sca.pdf}
}

@article{douglas_2023,
  title = {Data Quality in Online Human-Subjects Research: {{Comparisons}} between {{MTurk}}, {{Prolific}}, {{CloudResearch}}, {{Qualtrics}}, and {{SONA}}},
  shorttitle = {Data Quality in Online Human-Subjects Research},
  author = {Douglas, Benjamin D. and Ewell, Patrick J. and Brauer, Markus},
  year = {2023},
  month = mar,
  journal = {PLOS ONE},
  volume = {18},
  number = {3},
  pages = {e0279720},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0279720},
  urldate = {2024-10-04},
  abstract = {With the proliferation of online data collection in human-subjects research, concerns have been raised over the presence of inattentive survey participants and non-human respondents (bots). We compared the quality of the data collected through five commonly used platforms. Data quality was indicated by the percentage of participants who meaningfully respond to the researcher's question (high quality) versus those who only contribute noise (low quality). We found that compared to MTurk, Qualtrics, or an undergraduate student sample (i.e., SONA), participants on Prolific and CloudResearch were more likely to pass various attention checks, provide meaningful answers, follow instructions, remember previously presented information, have a unique IP address and geolocation, and work slowly enough to be able to read all the items. We divided the samples into high- and low-quality respondents and computed the cost we paid per high-quality respondent. Prolific (\$1.90) and CloudResearch (\$2.00) were cheaper than MTurk (\$4.36) and Qualtrics (\$8.17). SONA cost \$0.00, yet took the longest to collect the data.},
  langid = {english},
  keywords = {Attention,Ethnicities,Payment,Personality,Personality traits,Surveys,Undergraduates,United States},
  file = {C:\Users\mbch4gs2\Zotero\storage\E8Q8FA4D\Douglas et al. - 2023 - Data quality in online human-subjects research Comparisons between MTurk, Prolific, CloudResearch,.pdf}
}

@article{effectsize,
  title = {{{e}}ffectsize: {{Estimation}} of Effect Size Indices and Standardized Parameters},
  author = {{Ben-Shachar}, Mattan S. and L{\"u}decke, Daniel and Makowski, Dominique},
  year = {2020},
  journal = {Journal of Open Source Software},
  volume = {5},
  number = {56},
  pages = {2815},
  publisher = {The Open Journal},
  doi = {10.21105/joss.02815}
}

@manual{ematools,
  type = {Manual},
  title = {{{EMAtools}}: {{Data}} Management Tools for Real-Time Monitoring/Ecological Momentary Assessment Data},
  author = {Kleiman, Evan},
  year = {2021}
}

@misc{eprime_2020,
  title = {E-{{Prime}}},
  year = {2020},
  howpublished = {Psychology Software Tools}
}

@incollection{fechner_1948,
  title = {Elements of Psychophysics, 1860},
  booktitle = {Readings in the History of Psychology},
  author = {Fechner, Gustav Theodor},
  year = {1948},
  series = {Century Psychology Series},
  pages = {206--213},
  publisher = {Appleton-Century-Crofts},
  address = {East Norwalk, CT, US},
  doi = {10.1037/11304-026},
  abstract = {Fechner's modification of Weber's Law is the only part of Fechner's Elements of Psychophysics which has been published in English. It was translated by H. S. Langfeld, included in Rand's The Classical Psychologists, and is reprinted with the permission of the publishers and the translator. Weber's law forms merely the basis for the most numerous and important applications of psychic measurement, but not the universal and essential one. The most general and more fundamental basis for psychic measurement is rather those methods by which the relation between stimulus increments and sensation increment in general is determined, within, as well as without, the limits of Weber's law; and the development of these methods towards ever greater precision and perfection is the most important consideration in regard to psychic measurement. And yet a great advantage would be lost, if so simple a law as Weber's law could not be used as an exact or at least sufficiently approximate basis for psychic measurement. Although psychic measurement depends upon Weber's law only within limits in the domain of outer psycho-physics, it may well get its unconditional support from this law in the field of inner psychophysics. These are nevertheless for the present merely opinions and expectations, the verification of which lies in the future. The last half of this chapter addresses the fundamental formula and the measurement formula. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {History of Psychology,Mathematics,Psychometrics,Psychophysics,Theories},
  file = {C:\Users\mbch4gs2\Zotero\storage\A29899TJ\2006-10213-026.html}
}

@article{few_2008,
  title = {Solutions to the {{Problem}} of {{Over-Plotting}} in {{Graphs}}},
  author = {Few, Stephen},
  year = {2008},
  journal = {Visual Business Intelligence Newsletter},
  langid = {english},
  file = {C:\Users\mbch4gs2\Zotero\storage\YUTYMFEV\Few - 2008 - Solutions to the Problem of Over-Plotting in Graph.pdf}
}

@article{friendly_2005,
  title = {The Early Origins and Development of the Scatterplot.},
  author = {Friendly, M. and Denis, Daniel J.},
  year = {2005},
  journal = {Journal of the history of the behavioral sciences},
  doi = {10.1002/JHBS.20078},
  abstract = {It is suggested that the origin of this method can be traced to its unique advantage: the possibility to discover regularity in empirical data by smoothing and other graphic annotations to enhance visual perception. Of all the graphic forms used today, the scatterplot is arguably the most versatile, polymorphic, and generally useful invention in the history of statistical graphics. Its use by Galton led to the discovery of correlation and regression, and ultimately to much of present multivariate statistics. So, it is perhaps surprising that there is no one widely credited with the invention of this idea. Even more surprising is that there are few contenders for this title, and this question seems not to have been raised before. This article traces some of the developments in the history of this graphical method, the origin of the term scatterplot, the role it has played in the history of science, and some of its modern descendants. We suggest that the origin of this method can be traced to its unique advantage: the possibility to discover regularity in empirical data by smoothing and other graphic annotations to enhance visual perception.}
}

@article{garcia_2016,
  title = {Measuring {{Graph Literacy}} without a {{Test}}: {{A Brief Subjective Assessment}}},
  shorttitle = {Measuring {{Graph Literacy}} without a {{Test}}},
  author = {{Garcia-Retamero}, Rocio and Cokely, Edward T. and Ghazal, Saima and Joeris, Alexander},
  year = {2016},
  journal = {Medical Decision Making},
  volume = {36},
  number = {7},
  pages = {854--867},
  publisher = {SAGE Publications Inc STM},
  issn = {0272-989X},
  doi = {10.1177/0272989X16655334},
  urldate = {2021-04-30},
  abstract = {Background. Visual aids tend to help diverse and vulnerable individuals understand risk communications, as long as these individuals have a basic understanding of graphs (i.e., graph literacy). Tests of objective graph literacy (OGL) can effectively identify individuals with limited skills, highlighting vulnerabilities and facilitating custom-tailored risk communication. However, the administration of these tests can be time-consuming and may evoke negative emotional reactions (e.g., anxiety). Objectives. To evaluate a brief and easy-to-use assessment of subjective graph literacy (SGL) (i.e., self-reported ability to process and use graphically presented information) and to estimate the robustness and validity of the SGL scale and compare it with the leading OGL scale in diverse samples from different cultures. Participants. Demographically diverse residents (n = 470) of the United States, young adults (n = 172) and patients (n = 175) from Spain, and surgeons (n = 175) from 48 countries. Design. A focus group and 4 studies for instrument development and initial validation (study 1), reliability and convergent and discriminant validity evaluation (study 2), and predictive validity estimation (studies 3 and 4). Measures. Psychometric properties of the scale. Results. In about 1 minute, the SGL scale provides a reliable, robust, and valid assessment of skills and risk communication preferences and evokes fewer negative emotional reactions than the OGL scale. Conclusions. The SGL scale can be suitable for use in clinical research and may be useful as a communication aid in clinical practice. Theoretical mechanisms involved in SGL, emerging applications, limitations, and open questions are discussed.},
  langid = {english},
  keywords = {graph literacy,medical decision making,numeracy,risk communication,risk literacy,visual aids},
  file = {C:\Users\mbch4gs2\Zotero\storage\G3AA8J54\Garcia-Retamero et al. - 2016 - Measuring Graph Literacy without a Test A Brief S.pdf}
}

@article{ginsburg_2003,
  title = {Contrast {{Sensitivity}} and {{Functional Vision}}},
  author = {Ginsburg, Arthur P.},
  year = 2003,
  journal = {International Ophthalmology Clinics},
  volume = {43},
  number = {2},
  pages = {5},
  issn = {0020-8167},
  urldate = {2023-02-17},
  abstract = {An abstract is unavailable.},
  langid = {american},
  file = {C:\Users\mbch4gs2\Zotero\storage\KUEMRVAR\contrast_sensitivity_and_functional_vision.4.html}
}

@article{healey_2011,
  title = {Attention and {{Visual Memory}} in {{Visualization}} and {{Computer Graphics}}},
  author = {Healey, Christopher and Enns, James},
  year = {2011},
  month = jul,
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {18},
  number = {7},
  pages = {1170--1188},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2011.127},
  abstract = {A fundamental goal of visualization is to produce images of data that support visual analysis, exploration, and discovery of novel insights. An important consideration during visualization design is the role of human visual perception. How we "see'' details in an image can directly impact a viewer's efficiency and effectiveness. This paper surveys research on attention and visual perception, with a specific focus on results that have direct relevance to visualization and visual analytics. We discuss theories of low-level visual perception, then show how these findings form a foundation for more recent work on visual memory and visual attention. We conclude with a brief overview of how knowledge of visual attention and visual memory is being applied in visualization and graphics. We also discuss how challenges in visualization are motivating research in psychophysics.},
  keywords = {Attention,Bars,color,Data visualization,Feature extraction,Humans,motion,nonphotorealism,texture,visual memory,visual perception,Visual perception,Visualization,visualization.},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\C4R69TH5\\Healey - Attention and Visual Memory in Visualization and C.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\KHZWUVQZ\\5963660.html}
}

@article{hirao_2021,
  title = {Reliability of {{Online Surveys}} in {{Investigating Perceptions}} and {{Impressions}} of {{Faces}}},
  author = {Hirao, Naoyasu and Koizumi, Koyo and Ikeda, Hanako and Ohira, Hideki},
  year = {2021},
  month = sep,
  journal = {Frontiers in Psychology},
  volume = {12},
  publisher = {Frontiers},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2021.733405},
  urldate = {2024-10-04},
  abstract = {{$<$}p{$>$}Online experimental methods are used in psychological studies investigating the perceptions and impressions of facial photographs, even without substantial evidence supporting their reliability and validity. Although, the quality of visual stimuli is more difficult to control remotely, the methods might allow us to obtain a large amount of data. Then the statistical analysis of a larger volume of data may reduce errors and suggest significant difference in the stimuli. Therefore, we analyzed the reliability and validity of online surveys in investigating the perceptions (shine, red, and dark) and impressions (attractiveness, trustworthy, and so on) of facial photographs created from averaged faces with skin tones modified using computer graphics (CG). In this study, we conducted online (Online1) and laboratory experiments with well-controlled conditions (Control). For each experiment, 50 participants (men and women in Japan, age: 20--59years) completed the same questionnaire regarding their impressions of the same 28 CG facial photographs. The results showed significant correlations between the two experiments for all 19 items in the questionnaire. SD in the Online1 compared to the Control from the stimuli and individual differences were 56--84 and 88--104\% in each questionnaire items, respectively. Moreover, the rates of mismatching perceptual evaluations to the corresponding physical features demonstrated in the photographs were 4.9--9.7\% on average in an additional online survey of another 2,000 participants (Online2). These results suggest that online surveys can be applied to experiments to investigate impressions from CG facial photographs instead of general laboratory experiment by obtaining an appropriate number of participants to offset larger statistical errors that may result from the increased noise in the data from conducting the experiment online.{$<$}/p{$>$}},
  langid = {english},
  keywords = {Face,Impression,Online,Reliability - reproducibility of results,Survey},
  file = {C:\Users\mbch4gs2\Zotero\storage\P7HRDX7X\Hirao et al. - 2021 - Reliability of Online Surveys in Investigating Per.pdf}
}

@article{holmes_2021,
  title = {Reproducible Manuscript Preparation with {{RMarkdown}} Application to {{JMSACL}} and Other {{Elsevier Journals}}},
  author = {Holmes, Daniel T. and Mobini, Mahdi and McCudden, Christopher R.},
  year = {2021},
  month = nov,
  journal = {Journal of Mass Spectrometry and Advances in the Clinical Lab},
  volume = {22},
  pages = {8--16},
  issn = {2667145X},
  doi = {10.1016/j.jmsacl.2021.09.002},
  urldate = {2024-10-09},
  abstract = {Introduction: With the rising complexity of modern multimarker analytical techniques and notable scientific publication retractions required for erroneous statistical analysis, there is increasing awareness of the importance of research transparency and reproducibility. The development of mature open-source tools for literate programming in multiple langauge paradigms has made fully-reproducible authorship possible. Objectives: We describe the procedure for manuscript preparation using RMarkdown and the R statistical programming language with application to JMSACL or any other Elsevier journal. Methods: An instructional manuscript has been prepared in the RMarkdown markup language with stepwise directions on preparing sections, subsections, lists, tables, figures and reference management in an entirely reproducible format. Results: From RMarkdown code, a submission-ready PDF is generated and JMSACL-compatible LaTeX code is generated. These can be uploaded to the Editorial Manager. Conclusion: A completely reproducible manuscript preparation pipeline using the R and RMarkdown is described.},
  langid = {english},
  file = {C:\Users\mbch4gs2\Zotero\storage\PEQSK4WG\Holmes et al. - 2021 - Reproducible manuscript preparation with RMarkdown application to JMSACL and other Elsevier Journals.pdf}
}

@article{hong_2022,
  title = {The {{Weighted Average Illusion}}: {{Biases}} in {{Perceived Mean Position}} in {{Scatterplots}}},
  shorttitle = {The {{Weighted Average Illusion}}},
  author = {Hong, Matt-Heun and Witt, Jessica K. and Szafir, Danielle Albers},
  year = {2022},
  month = jan,
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {28},
  number = {01},
  pages = {987--997},
  publisher = {IEEE Computer Society},
  issn = {1077-2626},
  doi = {10.1109/TVCG.2021.3114783},
  urldate = {2025-01-28},
  abstract = {Scatterplots can encode a third dimension by using additional channels like size or color (e.g. bubble charts). We explore a potential misinterpretation of trivariate scatterplots, which we call the weighted average illusion, where locations of larger and darker points are given more weight toward x- and y-mean estimates. This systematic bias is sensitive to a designer's choice of size or lightness ranges mapped onto the data. In this paper, we quantify this bias against varying size/lightness ranges and data correlations. We discuss possible explanations for its cause by measuring attention given to individual data points using a vision science technique called the centroid method. Our work illustrates how ensemble processing mechanisms and mental shortcuts can significantly distort visual summaries of data, and can lead to misjudgments like the demonstrated weighted average illusion.},
  langid = {english},
  file = {C:\Users\mbch4gs2\Zotero\storage\5VR8Y9UN\Hong et al. - 2022 - The Weighted Average Illusion Biases in Perceived Mean Position in Scatterplots.pdf}
}

@manual{irr,
  type = {Manual},
  title = {Irr: {{Various}} Coefficients of Interrater Reliability and Agreement},
  author = {Gamer, Matthias and Lemon, Jim and {\textexclamdown}puspendra.pusp22@gmail.com{\textquestiondown}, Ian Fellows Puspendra Singh},
  year = {2019}
}

@misc{jimenez_2017,
  title = {Four Simple Recommendations to Encourage Best Practices in Research Software},
  author = {Jim{\'e}nez, Rafael C. and Kuzak, Mateusz and Alhamdoosh, Monther and Barker, Michelle and Batut, B{\'e}r{\'e}nice and Borg, Mikael and {Capella-Gutierrez}, Salvador and Hong, Neil Chue and Cook, Martin and Corpas, Manuel and Flannery, Madison and Garcia, Leyla and Gelp{\'i}, Josep Ll and Gladman, Simon and Goble, Carole and Ferreiro, Montserrat Gonz{\'a}lez and {Gonzalez-Beltran}, Alejandra and Griffin, Philippa C. and Gr{\"u}ning, Bj{\"o}rn and Hagberg, Jonas and Holub, Petr and Hooft, Rob and Ison, Jon and Katz, Daniel S. and Lesko{\v s}ek, Brane and G{\'o}mez, Federico L{\'o}pez and Oliveira, Luis J. and Mellor, David and Mosbergen, Rowland and Mulder, Nicola and {Perez-Riverol}, Yasset and Pergl, Robert and Pichler, Horst and Pope, Bernard and Sanz, Ferran and Schneider, Maria V. and Stodden, Victoria and Suchecki, Rados{\l}aw and Va{\v r}ekov{\'a}, Radka Svobodov{\'a} and Talvik, Harry-Anton and Todorov, Ilian and Treloar, Andrew and Tyagi, Sonika and van Gompel, Maarten and Vaughan, Daniel and Via, Allegra and Wang, Xiaochuan and {Watson-Haigh}, Nathan S. and Crouch, Steve},
  year = {2017},
  month = jun,
  number = {6:876},
  eprint = {6:876},
  publisher = {F1000Research},
  doi = {10.12688/f1000research.11407.1},
  urldate = {2024-10-15},
  abstract = {Scientific research relies on computer software, yet software is not always developed following practices that ensure its quality and sustainability. This manuscript does not aim to propose new software development best practices, but rather to provide simple recommendations that encourage the adoption of existing best practices. Software development best practices promote better quality software, and better quality software improves the reproducibility and reusability of research. These recommendations are designed around Open Source values, and provide practical suggestions that contribute to making research software and its source code more discoverable, reusable and transparent. This manuscript is aimed at developers, but also at organisations, projects, journals and funders that can increase the quality and sustainability of research software by encouraging the adoption of these recommendations.},
  archiveprefix = {F1000Research},
  copyright = {http://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  keywords = {best practices,code,FAIR,guidelines,Open Science,Open Source,quality,recommendations,software,sustainability},
  file = {C:\Users\mbch4gs2\Zotero\storage\3YJ86JIR\Jimnez et al. - 2017 - Four simple recommendations to encourage best practices in research software.pdf}
}

@article{klein_2018,
  title = {A {{Practical Guide}} for {{Transparency}} in {{Psychological Science}}},
  author = {Klein, Olivier and Hardwicke, Tom E. and Aust, Frederik and Breuer, Johannes and Danielsson, Henrik and Mohr, Alicia Hofelich and IJzerman, Hans and Nilsonne, Gustav and Vanpaemel, Wolf and Frank, Michael C.},
  editor = {Nuijten, Mich{\'e}le and Vazire, Simine},
  year = {2018},
  month = jun,
  journal = {Collabra: Psychology},
  volume = {4},
  number = {1},
  pages = {20},
  issn = {2474-7394},
  doi = {10.1525/collabra.158},
  urldate = {2024-10-10},
  abstract = {The credibility of scientific claims depends upon the transparency of the research products upon which they are based (e.g., study protocols, data, materials, and analysis scripts). As psychology navigates a period of unprecedented introspection, user-friendly tools and services that support open science have flourished. However, the plethora of decisions and choices involved can be bewildering. Here we provide a practical guide to help researchers navigate the process of preparing and sharing the products of their research (e.g., choosing a repository, preparing their research products for sharing, structuring folders, etc.). Being an open scientist means adopting a few straightforward research management practices, which lead to less error prone, reproducible research workflows. Further, this adoption can be piecemeal -- each incremental step towards complete transparency adds positive value. Transparent research practices not only improve the efficiency of individual researchers, they enhance the credibility of the knowledge generated by the scientific community.},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\3585JAT4\\Klein et al. - 2018 - A Practical Guide for Transparency in Psychological Science.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\EHXIGKUW\\A-Practical-Guide-for-Transparency-in.html}
}

@article{knuth_1984,
  title = {Literate {{Programming}}},
  author = {Knuth, D. E.},
  year = {1984},
  month = jan,
  journal = {The Computer Journal},
  volume = {27},
  number = {2},
  pages = {97--111},
  issn = {0010-4620},
  doi = {10.1093/comjnl/27.2.97},
  urldate = {2024-10-11},
  abstract = {The author and his associates have been experimenting for the past several years with a programming language and documentation system called WEB. This paper presents WEB by example, and discusses why the new system appears to be an improvement over previous ones.},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\Q3ZZPADJ\\Knuth - 1984 - Literate Programming.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\N6R56JJA\\343244.html}
}

@article{lane_1985,
  title = {Judging the {{Relatedness}} of {{Variables}}. {{The Psychophysics}} of {{Covariation Detection}}},
  author = {Lane, David and Anderson, Craig and Kellam, Kathryn},
  year = {1985},
  month = oct,
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  volume = {11},
  pages = {640--649},
  doi = {10.1037/0096-1523.11.5.640},
  abstract = {Conducted 3 experiments to demonstrate that because Pearson's correlation is composed of 3 distinct components (slope, error variance, and variance of  X), it is better to look at judgments as a function of these components rather than as a function of Pearson's correlation. These 3 components of Pearson's correlation and presentation format (graphical and tabular) were manipulated factorially. The 1st 2 experiments used naive Ss (79 undergraduates), and the 3rd experiment used expert Ss (25 professionals knowledgeable in statistics). Scatterplots with the same value of Pearson's correlation were judged to possess different degrees of relation if the correlations were based on different combinations of the 3 components. With Pearson's correlation held constant, the error variance was the most important component. Graphical formats led to higher judgments of relatedness than did tabular formats, with this effect being larger for naive than for expert Ss. It is also concluded that attempts to determine the psychophysical function between Pearson's correlation and judgments of relatedness are of questionable value. (10 ref) (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  keywords = {Judgment,Psychophysiology,Statistical Correlation,Statistical Variables},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\T9WVGCYU\\Lane et al. - 1985 - Judging the Relatedness of Variables. The Psychoph.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\ZZWYAXMG\\1986-13490-001.html}
}

@article{lauer_1989,
  title = {Density in Scatterplots and the Estimation of Correlation},
  author = {Lauer, Thomas W. and Post, Gerald V.},
  year = {1989},
  month = jun,
  journal = {Behaviour \& Information Technology},
  volume = {8},
  number = {3},
  pages = {235--244},
  issn = {0144-929X, 1362-3001},
  doi = {10.1080/01449298908914554},
  urldate = {2023-09-05},
  abstract = {Abstract The construction of a graphical presentation involves the representation of information by means of visual symbols. The acquisition of information from the resultant graph is a perceptual process that involves the decoding and interpretation of the visual symbols. Hence good design decisions will be based on an understanding of the information acquisition process and in particular graphical perception. This study examines the perception of bivariate normal data presented in a scatter diagram, and creates a model that successfully explains how individuals perceive the information contained in scatterplots Subjects were shown a series of scatter diagrams on the CRT of a microcomputer and were asked to estimate correlation. Several variables were examined that explain estimated correlation including regression slope, dispersion, number of points displayed, and the size of the CRT screen. All of these factors were found to significantly affect subjects' estimates of correlation.},
  langid = {english}
}

@article{leisch_2002,
  title = {Sweave, Part {{I}}: {{Mixing R}} and {{LaTeX}}},
  shorttitle = {Sweave, Part {{I}}},
  author = {Leisch, Friedrich},
  year = {2002},
  month = dec,
  journal = {R News},
  volume = {2},
  number = {3},
  pages = {28--31},
  issn = {1609-3631},
  urldate = {2024-10-09},
  abstract = {"Sweave, part I: Mixing R and LaTeX" published in R News.}
}

@manual{lenth_2024,
  type = {Manual},
  title = {Emmeans: {{Estimated}} Marginal Means, Aka Least-Squares Means},
  author = {Lenth, Russell V.},
  year = {2024}
}

@article{li_2021,
  title = {Visualizing {{COVID-19}} Information for Public: {{Designs}}, Effectiveness, and Preference of Thematic Maps},
  shorttitle = {Visualizing {{COVID-19}} Information for Public},
  author = {Li, Rui},
  year = {2021},
  journal = {Human Behavior and Emerging Technologies},
  volume = {3},
  number = {1},
  pages = {97--106},
  issn = {2578-1863},
  doi = {10.1002/hbe2.248},
  urldate = {2024-10-22},
  abstract = {The unprecedented COVID-19 pandemic has affected human lives at all levels. Maps visualizing this pandemic have become a valuable tool for public to retrieve and understand the situation in their areas of interest. Some earlier maps visualize information at the level of country or state in the United States, but viewers could not access information at a finer level such as county. Motivated by the necessity of visualizing information at a finer level, this study designs a thematic map displaying confirmed COVID-19 cases at the county level in the State of New York. The thematic map utilizes a choropleth design with defined data classification and colors for symbolization. This study then evaluates this designed thematic map with two other published maps: one from the New York State Department of Health and one from The New York Times. The evaluation collects 147 valid responses from public all over the world. Results show that choropleth design yields higher accuracy of map understanding. In addition, the designed map in this study receives higher preference among participants. This study suggests the importance of understanding the data, readers, and mapping purpose in the decision of data classification and symbolization in map design, as it contributes largely to the effectiveness of map interpretation.},
  copyright = {{\copyright} 2021 Wiley Periodicals LLC.},
  langid = {english},
  keywords = {cartography,choropleth map,COVID-19,effectiveness,human cognition,interpretation,map design,proportional symbol,thematic map,web map},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\TXUARDMH\\Li - 2021 - Visualizing COVID-19 information for public Designs, effectiveness, and preference of thematic maps.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\VIDLL4I6\\hbe2.html}
}

@article{liddell_2018,
  title = {Analyzing Ordinal Data with Metric Models: {{What}} Could Possibly Go Wrong?},
  shorttitle = {Analyzing Ordinal Data with Metric Models},
  author = {Liddell, Torrin M. and Kruschke, John K.},
  year = {2018},
  month = nov,
  journal = {Journal of Experimental Social Psychology},
  volume = {79},
  pages = {328--348},
  issn = {0022-1031},
  doi = {10.1016/j.jesp.2018.08.009},
  urldate = {2024-09-03},
  abstract = {We surveyed all articles in the Journal of Personality and Social Psychology (JPSP), Psychological Science (PS), and the Journal of Experimental Psychology: General (JEP:G) that mentioned the term ``Likert,'' and found that 100\% of the articles that analyzed ordinal data did so using a metric model. We present novel evidence that analyzing ordinal data as if they were metric can systematically lead to errors. We demonstrate false alarms (i.e., detecting an effect where none exists, Type I errors) and failures to detect effects (i.e., loss of power, Type II errors). We demonstrate systematic inversions of effects, for which treating ordinal data as metric indicates the opposite ordering of means than the true ordering of means. We show the same problems --- false alarms, misses, and inversions --- for interactions in factorial designs and for trend analyses in regression. We demonstrate that averaging across multiple ordinal measurements does not solve or even ameliorate these problems. A central contribution is a graphical explanation of how and when the misrepresentations occur. Moreover, we point out that there is no sure-fire way to detect these problems by treating the ordinal values as metric, and instead we advocate use of ordered-probit models (or similar) because they will better describe the data. Finally, although frequentist approaches to some ordered-probit models are available, we use Bayesian methods because of their flexibility in specifying models and their richness and accuracy in providing parameter estimates. An R script is provided for running an analysis that compares ordered-probit and metric models.},
  keywords = {Bayesian analysis,Likert,Ordered-probit,Ordinal data},
  file = {C:\Users\mbch4gs2\Zotero\storage\ILW7PTGH\Liddell and Kruschke - 2018 - Analyzing ordinal data with metric models What co.pdf}
}

@article{logg_2021,
  title = {Pre-Registration: {{Weighing}} Costs and Benefits for Researchers},
  shorttitle = {Pre-Registration},
  author = {Logg, Jennifer M. and Dorison, Charles A.},
  year = {2021},
  month = nov,
  journal = {Organizational Behavior and Human Decision Processes},
  volume = {167},
  pages = {18--27},
  issn = {0749-5978},
  doi = {10.1016/j.obhdp.2021.05.006},
  urldate = {2024-10-10},
  abstract = {In the past decade, the social and behavioral sciences underwent a methodological revolution, offering practical prescriptions for improving the replicability and reproducibility of research results. One key to reforming science is a simple and scalable practice: pre-registration. Pre-registration constitutes pre-specifying an analysis plan prior to data collection. A growing chorus of articles discusses the prescriptive, field-wide benefits of pre-registration. To increase adoption, however, scientists need to know who currently pre-registers and understand perceived barriers to doing so. Thus, we weigh costs and benefits of pre-registration. Our survey of researchers reveals generational differences in who pre-registers and uncertainty regarding how pre-registration benefits individual researchers. We leverage these data to directly address researchers' uncertainty by clarifying why pre-registration improves the research process itself. Finally, we discuss how to pre-register and compare available resources. The present work examines the who, why, and how of pre-registration in order to weigh the costs and benefits of pre-registration to researchers and motivate continued adoption.},
  keywords = {Methodology,Open science,Pre-registration,Replication},
  file = {C:\Users\mbch4gs2\Zotero\storage\6BXITKGV\S0749597821000649.html}
}

@inproceedings{matejka_2015,
  title = {Dynamic {{Opacity Optimization}} for {{Scatter Plots}}},
  booktitle = {Proceedings of the 33rd {{Annual ACM Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Matejka, Justin and Anderson, Fraser and Fitzmaurice, George},
  year = {2015},
  month = apr,
  pages = {2707--2710},
  publisher = {ACM},
  address = {Seoul Republic of Korea},
  doi = {10.1145/2702123.2702585},
  urldate = {2021-10-18},
  abstract = {Scatterplots are an effective and commonly used technique to show the relationship between two variables. However, as the number of data points increases, the chart suffers from ``over-plotting'' which obscures data points and makes the underlying distribution of the data difficult to discern. Reducing the opacity of the data points is an effective way to address over-plotting, however, setting the individual point opacity is a manual task performed by the chart designer. We present a user-driven model of opacity scaling for scatter plots built from crowd-sourced responses to opacity scaling tasks using several synthetic data distributions, and then test our model on a collection of real-world data sets.},
  isbn = {978-1-4503-3145-6},
  langid = {english},
  file = {C:\Users\mbch4gs2\Zotero\storage\2U7AUV2V\Matejka et al. - 2015 - Dynamic Opacity Optimization for Scatter Plots.pdf}
}

@article{mathot_2012,
  title = {{{OpenSesame}}: {{An}} Open-Source, Graphical Experiment Builder for the Social Sciences},
  shorttitle = {{{OpenSesame}}},
  author = {Math{\^o}t, Sebastiaan and Schreij, Daniel and Theeuwes, Jan},
  year = {2012},
  journal = {Behavior Research Methods},
  volume = {44},
  number = {2},
  pages = {314--324},
  issn = {1554-351X},
  doi = {10.3758/s13428-011-0168-7},
  urldate = {2024-10-03},
  abstract = {In the present article, we introduce OpenSesame, a graphical experiment builder for the social sciences. OpenSesame is free, open-source, and cross-platform. It features a comprehensive and intuitive graphical user interface and supports Python scripting for complex tasks. Additional functionality, such as support for eyetrackers, input devices, and video playback, is available through plug-ins. OpenSesame can be used in combination with existing software for creating experiments.},
  pmcid = {PMC3356517},
  pmid = {22083660},
  file = {C:\Users\mbch4gs2\Zotero\storage\RLJFCGWK\Matht et al. - 2012 - OpenSesame An open-source, graphical experiment b.pdf}
}

@article{merkel_2014,
  title = {Docker: Lightweight {{Linux}} Containers for Consistent Development and Deployment},
  shorttitle = {Docker},
  author = {Merkel, Dirk},
  year = {2014},
  month = mar,
  journal = {Linux J.},
  volume = {2014},
  number = {239},
  pages = {2:2},
  issn = {1075-3583},
  abstract = {Docker promises the ability to package applications and their dependencies into lightweight containers that move easily between different distros, start up quickly and are isolated from each other.}
}

@article{meteyard_2020,
  title = {Best Practice Guidance for Linear Mixed-Effects Models in Psychological Science},
  author = {Meteyard, Lotte and Davies, Robert A. I.},
  year = {2020},
  month = jun,
  journal = {Journal of Memory and Language},
  volume = {112},
  pages = {104092},
  issn = {0749-596X},
  doi = {10.1016/j.jml.2020.104092},
  urldate = {2024-10-09},
  abstract = {The use of Linear Mixed-effects Models (LMMs) is set to dominate statistical analyses in psychological science and may become the default approach to analyzing quantitative data. The rapid growth in adoption of LMMs has been matched by a proliferation of differences in practice. Unless this diversity is recognized, and checked, the field shall reap enormous difficulties in the future when attempts are made to consolidate or synthesize research findings. Here we examine this diversity using two methods -- a survey of researchers (n~=~163) and a quasi-systematic review of papers using LMMs (n~=~400). The survey reveals substantive concerns among psychologists using or planning to use LMMs and an absence of agreed standards. The review of papers complements the survey, showing variation in how the models are built, how effects are evaluated and, most worryingly, how models are reported. Using these data as our departure point, we present a set of best practice guidance, focusing on the reporting of LMMs. It is the authors' intention that the paper supports a step-change in the reporting of LMMs across the psychological sciences, preventing a trajectory in which findings reported today cannot be transparently understood and used tomorrow.},
  keywords = {Hierarchical models,Linear mixed effects models,Multilevel models},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\D465EMBS\\Meteyard and Davies - 2020 - Best practice guidance for linear mixed-effects models in psychological science.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\TDDPQS6U\\S0749596X20300061.html}
}

@article{meyer_1992,
  title = {Estimating {{Correlations}} from {{Scatterplots}}},
  author = {Meyer, Joachim and Shinar, David},
  year = {1992},
  month = jun,
  journal = {Human Factors},
  volume = {34},
  number = {3},
  pages = {335--349},
  publisher = {SAGE Publications Inc},
  issn = {0018-7208},
  doi = {10.1177/001872089203400307},
  urldate = {2022-06-09},
  abstract = {Previous attempts to establish the function relating intuitive estimates of correlations from scatterplots to accepted statistical measures have led to unsatisfying results. In this study two experiments dealt with the effects of the statistical training of the viewer and various characteristics of the display on estimates. Statistical knowledge was related to higher estimates of correlations and the use of a wider range of values, but people with and without statistical knowledge were equally affected by the type of dispersion of the point cloud, the mere display of the regression line, and the slope of the regression line. Results indicate that estimates of correlations from scatterplots are partly based on perceptual processes that are influenced by visual properties of the display and are unrelated to the cognitive structures created by formal statistical training.},
  file = {C:\Users\mbch4gs2\Zotero\storage\LHY2G6W7\Meyer and Shinar - 1992 - Estimating Correlations from Scatterplots.pdf}
}

@article{meyer_1997,
  title = {Correlation Estimates as Perceptual Judgments},
  author = {Meyer, Joachim and Taieb, Meirav and Flascher, Ittai},
  year = {1997},
  journal = {Journal of Experimental Psychology: Applied},
  volume = {3},
  number = {1},
  pages = {3--20},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-2192},
  doi = {10.1037/1076-898X.3.1.3},
  abstract = {Correlation estimates from scatterplots were studied as an example for an intuitive decision task. Three experiments showed that subjective correlation estimates are based on geometric properties of the displays. People with different levels of statistical training were found to assess correlations from scatterplots in close accordance with the power function rest{\enspace}={\enspace}1{\enspace}--{\enspace}aXb, where X is the mean of the geometrical distances between the points and the regression line or a similar central axis. Changes of the slope of the displayed point cloud and the introduction of outliers affected estimates as predicted from the function. The study demonstrated that intuitive judgments in a complex domain are based on the perception of geometric features of the relevant information. By applying these findings, graphic designers can accurately predict how changes in a display will affect viewers' impressions. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Decision Making,Graphical Displays,Intuition,Perceptual Localization,Psychophysics,Statistical Correlation,Statistical Estimation,Visual Perception},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\LMY56GZV\\Meyer et al. - 1997 - Correlation estimates as perceptual judgments.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\99EDEJKQ\\1997-03016-001.html}
}

@article{midway_2020,
  title = {Principles of {{Effective Data Visualization}}},
  author = {Midway, Stephen R.},
  year = {2020},
  month = dec,
  journal = {Patterns},
  volume = {1},
  number = {9},
  publisher = {Elsevier},
  issn = {2666-3899},
  doi = {10.1016/j.patter.2020.100141},
  urldate = {2024-10-22},
  langid = {english},
  pmid = {33336199},
  keywords = {DSML 5: Mainstream: Data science output is well understood and (nearly) universally adopted}
}

@misc{mit,
  title = {The {{MIT License}}},
  journal = {Open Source Initiative},
  urldate = {2024-10-15},
  abstract = {Copyright {$<$}YEAR{$>$} {$<$}COPYRIGHT HOLDER{$>$} Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ``Software''), to deal in the{\dots}},
  howpublished = {https://opensource.org/license/mit},
  langid = {american},
  file = {C:\Users\mbch4gs2\Zotero\storage\IAPVYP6I\mit.html}
}

@article{miyakawa_2020,
  title = {No Raw Data, No Science: Another Possible Source of the Reproducibility Crisis},
  shorttitle = {No Raw Data, No Science},
  author = {Miyakawa, Tsuyoshi},
  year = {2020},
  month = feb,
  journal = {Molecular Brain},
  volume = {13},
  number = {1},
  pages = {24},
  issn = {1756-6606},
  doi = {10.1186/s13041-020-0552-2},
  urldate = {2024-10-10},
  abstract = {A reproducibility crisis is a situation where many scientific studies cannot be reproduced. Inappropriate practices of science, such as HARKing, p-hacking, and selective reporting of positive results, have been suggested as causes of irreproducibility. In this editorial, I propose that a lack of raw data or data fabrication is another possible cause of irreproducibility.},
  langid = {english},
  keywords = {Data fabrication,Misconduct,Open data,Open science,Raw data,Reproducibility},
  file = {C:\Users\mbch4gs2\Zotero\storage\BPQXUGPR\Miyakawa - 2020 - No raw data, no science another possible source of the reproducibility crisis.pdf}
}

@article{nakagawa_2013,
  title = {A General and Simple Method for Obtaining {{R2}} from Generalized Linear Mixed-Effects Models},
  author = {Nakagawa, Shinichi and Schielzeth, Holger},
  year = {2013},
  journal = {Methods in Ecology and Evolution},
  volume = {4},
  number = {2},
  pages = {133--142},
  issn = {2041-210X},
  doi = {10.1111/j.2041-210x.2012.00261.x},
  urldate = {2023-09-07},
  abstract = {The use of both linear and generalized linear mixed-effects models (LMMs and GLMMs) has become popular not only in social and medical sciences, but also in biological sciences, especially in the field of ecology and evolution. Information criteria, such as Akaike Information Criterion (AIC), are usually presented as model comparison tools for mixed-effects models. The presentation of `variance explained' (R2) as a relevant summarizing statistic of mixed-effects models, however, is rare, even though R2 is routinely reported for linear models (LMs) and also generalized linear models (GLMs). R2 has the extremely useful property of providing an absolute value for the goodness-of-fit of a model, which cannot be given by the information criteria. As a summary statistic that describes the amount of variance explained, R2 can also be a quantity of biological interest. One reason for the under-appreciation of R2 for mixed-effects models lies in the fact that R2 can be defined in a number of ways. Furthermore, most definitions of R2 for mixed-effects have theoretical problems (e.g. decreased or negative R2 values in larger models) and/or their use is hindered by practical difficulties (e.g. implementation). Here, we make a case for the importance of reporting R2 for mixed-effects models. We first provide the common definitions of R2 for LMs and GLMs and discuss the key problems associated with calculating R2 for mixed-effects models. We then recommend a general and simple method for calculating two types of R2 (marginal and conditional R2) for both LMMs and GLMMs, which are less susceptible to common problems. This method is illustrated by examples and can be widely employed by researchers in any fields of research, regardless of software packages used for fitting mixed-effects models. The proposed method has the potential to facilitate the presentation of R2 for a wide range of circumstances.},
  langid = {english},
  keywords = {coefficient of determination,goodness-of-fit,heritability,information criteria,intra-class correlation,linear models,model fit,repeatability,variance explained},
  file = {C:\Users\mbch4gs2\Zotero\storage\B82C6FKK\j.2041-210x.2012.00261.html}
}

@article{nocke_2008,
  title = {Visualization of Climate and Climate Change Data: {{An}} Overview},
  author = {Nocke, Thomas and Sterzel, Till and B{\"o}ttinger, Michael and Wrobel, Markus and others},
  year = {2008},
  journal = {Digital earth summit on geoinformatics},
  pages = {226--232},
  publisher = {Citeseer}
}

@manual{ordinal,
  type = {Manual},
  title = {Ordinal---Regression Models for Ordinal Data},
  author = {Christensen, Rune H. B.},
  year = {2023}
}

@misc{OSF,
  title = {{{OSF}}},
  urldate = {2024-10-10},
  howpublished = {https://osf.io/},
  file = {C:\Users\mbch4gs2\Zotero\storage\KLJEZPC6\osf.io.html}
}

@article{osf_2015,
  title = {Estimating the Reproducibility of Psychological Science},
  author = {{Open Science Collaboration}},
  year = {2015},
  month = aug,
  journal = {Science},
  volume = {349},
  number = {6251},
  pages = {aac4716},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.aac4716},
  urldate = {2024-10-10},
  abstract = {Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
  file = {C:\Users\mbch4gs2\Zotero\storage\3FB659IC\Open Science Collaboration - 2015 - Estimating the reproducibility of psychological science.pdf}
}

@misc{pandoc,
  title = {Pandoc},
  author = {MacFarlane, John},
  urldate = {2024-10-09},
  howpublished = {https://pandoc.org/index.html},
  file = {C:\Users\mbch4gs2\Zotero\storage\J4KGFDGI\index.html}
}

@article{peer_2021,
  title = {Data Quality of Platforms and Panels for Online Behavioral Research},
  author = {Peer, Eyal and Rothschild, David and Gordon, Andrew and Evernden, Zak and Damer, Ekaterina},
  year = {2021},
  month = sep,
  journal = {Behavior Research Methods},
  volume = {54},
  number = {4},
  pages = {1643--1662},
  issn = {1554-3528},
  doi = {10.3758/s13428-021-01694-3},
  urldate = {2022-07-05},
  abstract = {We examine key aspects of data quality for online behavioral research between selected platforms (Amazon Mechanical Turk, CloudResearch, and Prolific) and panels (Qualtrics and Dynata). To identify the key aspects of data quality, we first engaged with the behavioral research community to discover which aspects are most critical to researchers and found that these include attention, comprehension, honesty, and reliability. We then explored differences in these data quality aspects in two studies (N\,{\textasciitilde}\,4000), with or without data quality filters (approval ratings). We found considerable differences between the sites, especially in comprehension, attention, and dishonesty. In Study 1 (without filters), we found that only Prolific provided high data quality on all measures. In Study 2 (with filters), we found high data quality among CloudResearch and Prolific. MTurk showed alarmingly low data quality even with data quality filters. We also found that while reputation (approval rating) did not predict data quality, frequency and purpose of usage did, especially on MTurk: the lowest data quality came from MTurk participants who report using the site as their main source of income but spend few hours on it per week. We provide a framework for future investigation into the ever-changing nature of data quality in online research, and how the evolving set of platforms and panels performs on these key aspects.},
  langid = {english},
  keywords = {Amazon mechanical turk,Attention,Comprehension,Data quality,Honesty,Online research,Prolific,Reliability},
  file = {C:\Users\mbch4gs2\Zotero\storage\YY2VD7W8\Peer et al. - 2021 - Data quality of platforms and panels for online be.pdf}
}

@article{peirce_2019,
  title = {{{PsychoPy2}}: {{Experiments}} in Behavior Made Easy},
  shorttitle = {{{PsychoPy2}}},
  author = {Peirce, Jonathan and Gray, Jeremy R. and Simpson, Sol and MacAskill, Michael and H{\"o}chenberger, Richard and Sogo, Hiroyuki and Kastman, Erik and Lindel{\o}v, Jonas Kristoffer},
  year = {2019},
  month = feb,
  journal = {Behavior Research Methods},
  volume = {51},
  number = {1},
  pages = {195--203},
  issn = {1554-3528},
  doi = {10.3758/s13428-018-01193-y},
  abstract = {PsychoPy is an application for the creation of experiments in behavioral science (psychology, neuroscience, linguistics, etc.) with precise spatial control and timing of stimuli. It now provides a choice of interface; users can write scripts in Python if they choose, while those who prefer to construct experiments graphically can use the new Builder interface. Here we describe the features that have been added over the last 10 years of its development. The most notable addition has been that Builder interface, allowing users to create studies with minimal or no programming, while also allowing the insertion of Python code for maximal flexibility. We also present some of the other new features, including further stimulus options, asynchronous time-stamped hardware polling, and better support for open science and reproducibility. Tens of thousands of users now launch PsychoPy every month, and more than 90 people have contributed to the code. We discuss the current state of the project, as well as plans for the future.},
  langid = {english},
  pmcid = {PMC6420413},
  pmid = {30734206},
  keywords = {Behavioral Research,Experiment,Humans,Open science,Open-source,Psychology,Reaction time,Reproducibility of Results,Software,Timing,User-Computer Interface},
  file = {C:\Users\mbch4gs2\Zotero\storage\93ITF788\Peirce et al. - 2019 - PsychoPy2 Experiments in behavior made easy.pdf}
}

@article{peng_2011,
  title = {Reproducible {{Research}} in {{Computational Science}}},
  author = {Peng, Roger D.},
  year = {2011},
  month = dec,
  journal = {Science},
  volume = {334},
  number = {6060},
  pages = {1226--1227},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.1213847},
  urldate = {2024-10-09},
  abstract = {Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.},
  file = {C:\Users\mbch4gs2\Zotero\storage\UDVSLPAC\Peng - 2011 - Reproducible Research in Computational Science.pdf}
}

@article{peng_2015,
  title = {The Reproducibility Crisis in Science: {{A}} Statistical Counterattack},
  shorttitle = {The Reproducibility Crisis in Science},
  author = {Peng, Roger},
  year = {2015},
  journal = {Significance},
  volume = {12},
  number = {3},
  pages = {30--32},
  issn = {1740-9713},
  doi = {10.1111/j.1740-9713.2015.00827.x},
  urldate = {2024-10-10},
  abstract = {More people have more access to data than ever before. But a comparative lack of analytical skills has resulted in scientific findings that are neither replicable nor reproducible. It is time to invest in statistics education, says Roger Peng},
  langid = {english},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\9ZE5DNCP\\Peng - 2015 - The reproducibility crisis in science A statistical counterattack.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\HBYIDUMV\\j.1740-9713.2015.00827.html}
}

@article{piccolo_2016,
  title = {Tools and Techniques for Computational Reproducibility},
  author = {Piccolo, Stephen R and Frampton, Michael B},
  year = {2016},
  month = dec,
  journal = {GigaScience},
  volume = {5},
  number = {1},
  pages = {s13742-016-0135-4},
  issn = {2047-217X},
  doi = {10.1186/s13742-016-0135-4},
  urldate = {2024-10-09},
  abstract = {When reporting research findings, scientists document the steps they followed so that others can verify and build upon the research. When those steps have been described in sufficient detail that others can retrace the steps and obtain similar results, the research is said to be reproducible. Computers play a vital role in many research disciplines and present both opportunities and challenges for reproducibility. Computers can be programmed to execute analysis tasks, and those programs can be repeated and shared with others. The deterministic nature of most computer programs means that the same analysis tasks, applied to the same data, will often produce the same outputs. However, in practice, computational findings often cannot be reproduced because of complexities in how software is packaged, installed, and executed---and because of limitations associated with how scientists document analysis steps. Many tools and techniques are available to help overcome these challenges; here we describe seven such strategies. With a broad scientific audience in mind, we describe the strengths and limitations of each approach, as well as the circumstances under which each might be applied. No single strategy is sufficient for every scenario; thus we emphasize that it is often useful to combine approaches.},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\77UXH3QG\\Piccolo and Frampton - 2016 - Tools and techniques for computational reproducibility.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\4LCTUVIA\\2720991.html}
}

@article{potti_2006,
  title = {Genomic Signatures to Guide the Use of Chemotherapeutics},
  author = {A, Potti and Hk, Dressman and A, Bild and Rf, Riedel and G, Chan and R, Sayer and J, Cragun and H, Cottrill and Mj, Kelley and R, Petersen and D, Harpole and J, Marks and A, Berchuck and Gs, Ginsburg and P, Febbo and J, Lancaster and Jr, Nevins},
  year = {2006},
  month = nov,
  journal = {Nature medicine},
  volume = {12},
  number = {11},
  publisher = {Nat Med},
  issn = {1078-8956},
  doi = {10.1038/nm1491},
  urldate = {2024-10-10},
  abstract = {Using in vitro drug sensitivity data coupled with Affymetrix microarray data, we developed gene expression signatures that predict sensitivity to individual chemotherapeutic drugs. Each signature was validated with response data from an independent set of cell line studies. We further show that many {\dots}},
  langid = {english},
  pmid = {17057710},
  file = {C:\Users\mbch4gs2\Zotero\storage\PBAL76CI\17057710.html}
}

@article{prisse_2022,
  title = {Lab vs Online Experiments: {{No}} Differences},
  shorttitle = {Lab vs Online Experiments},
  author = {Priss{\'e}, Benjamin and Jorrat, Diego},
  year = {2022},
  month = oct,
  journal = {Journal of Behavioral and Experimental Economics},
  volume = {100},
  pages = {101910},
  issn = {2214-8043},
  doi = {10.1016/j.socec.2022.101910},
  urldate = {2024-10-04},
  abstract = {We ran an experiment to study whether not controlling, or the lack of control, of the experimental environment has an effect on experimental results. Subjects were recruited following standard procedures and randomly assigned to complete the experiment online or in the laboratory. The experimental design is otherwise identical between conditions. The results suggest that there are no differences between conditions, except for a larger percentage of online subjects who donate nothing in the Dictator Game.},
  keywords = {CTB,Experiments,Time preferences},
  file = {C:\Users\mbch4gs2\Zotero\storage\LU9C4H4S\S2214804322000842.html}
}

@misc{prolific,
  title = {Prolific.Co},
  year = {2024},
  howpublished = {Prolific}
}

@manual{r_core,
  type = {Manual},
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  year = {2024},
  address = {Vienna, Austria},
  institution = {R Foundation for Statistical Computing}
}

@manual{r2glmm,
  type = {Manual},
  title = {R2glmm: {{Computes R}} Squared for Mixed (Multilevel) Models},
  author = {Jaeger, Byron},
  year = {2017}
}

@article{rensink_2010,
  title = {The {{Perception}} of {{Correlation}} in {{Scatterplots}}},
  author = {Rensink, Ronald A. and Baldridge, Gideon},
  year = {2010},
  month = aug,
  journal = {Computer Graphics Forum},
  volume = {29},
  number = {3},
  pages = {1203--1210},
  issn = {01677055},
  doi = {10.1111/j.1467-8659.2009.01694.x},
  urldate = {2021-02-02},
  abstract = {We present a rigorous way to evaluate the visual perception of correlation in scatterplots, based on classical psychophysical methods originally developed for simple properties such as brightness. Although scatterplots are graphically complex, the quantity they convey is relatively simple. As such, it may be possible to assess the perception of correlation in a similar way.},
  langid = {english},
  file = {C:\Users\mbch4gs2\Zotero\storage\TJJGGFI9\Rensink and Baldridge - 2010 - The Perception of Correlation in Scatterplots.pdf}
}

@inproceedings{rensink_2012,
  title = {Invariance of {{Correlation Perception}}},
  booktitle = {Journal of {{Vision}}},
  author = {Rensink, Ronald},
  year = {2012},
  month = may,
  volume = {12},
  pages = {433--433},
  publisher = {Vision Sciences Society},
  doi = {10.1167/12.9.433},
  abstract = {Previous work has shown that the perception of correlation in scatterplots can be characterized by two simple laws: a linear Fechner-like law for precision and a logarithmic Weber-like law for accuracy (Rensink \& Baldridge, 2010). It also appears to be rapid, being largely complete within 100 ms of presentation (Rensink, 2011). This suggests that although correlation may be conveyed by a complex carrier, it nevertheless is-or at least, is based on-a relatively simple property. To investigate the nature of the process involved, two sets of experiments tested whether different kinds of visual design influence correlation perception. The first set involved scatterplots with various styles of dot (or symbol). Precision was determined via the just noticeable difference in correlation for two side-by-side scatterplots. Accuracy was determined by direct estimation, using reference scatterplots having fixed upper and lower values, and a test scatterplot adjusted to have its apparent correlation be midway between them. The second set used similar methodology but a different carrier, with the vertical position carrying the second data dimension being replaced by a simple feature such as size. Such `augmented stripplots' then conveyed correlation via the relation between horizontal position and size. Twelve observers were tested in each condition. Results showed a surprising degree of invariance for scatterplot symbol: different sizes, colors, and even shapes had little effect on precision or accuracy. This suggests that only the centers of the symbols are relevant, ruling out the involvement of simple operations such as blurring. In addition, there was also an interesting degree of invariance for carrier: accuracy and precision in augmented stripplots obeyed linear-logarithmic laws similar to those for scatterplots. These invariances suggest that correlation perception may be a general process that is both rapid and sophisticated.},
  file = {C:\Users\mbch4gs2\Zotero\storage\8A6DIYR4\Rensink - 2012 - Invariance of Correlation Perception.pdf}
}

@incollection{rensink_2014,
  title = {On the {{Prospects}} for a {{Science}} of {{Visualization}}},
  booktitle = {Handbook of {{Human Centric Visualization}}},
  author = {Rensink, Ronald A.},
  editor = {Huang, Weidong},
  year = {2014},
  pages = {147--175},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-1-4614-7485-2_6},
  urldate = {2022-06-15},
  abstract = {This paper explores the extent to which a scientific framework for visualization might be possible. It presents several potential parts of a framework, illustrated by application to the visualization of correlation in scatterplots. The first is an extended-vision thesis, which posits that a viewer and visualization system can be usefully considered as a single system that perceives structure in a dataset, much like "basic" vision perceives structure in the world. This characterization is then used to suggest approaches to evaluation that take advantage of techniques used in vision science. Next, an optimal-reduction thesis is presented, which posits that an optimal visualization enables the given task to be reduced to the most suitable operations in the extended system. A systematic comparison of alternative designs is then proposed, guided by what is known about perceptual mechanisms. It is shown that these elements can be extended in various ways---some even overlapping with parts of vision science. As such, a science of some kind appears possible for at least some parts of visualization. It would remain distinct from design practice, but could nevertheless assist with the design of visualizations that better engage human perception and cognition.},
  isbn = {978-1-4614-7484-5 978-1-4614-7485-2},
  langid = {english},
  file = {C:\Users\mbch4gs2\Zotero\storage\H3BGUW5H\Rensink - 2014 - On the Prospects for a Science of Visualization.pdf}
}

@article{rensink_2017,
  title = {The Nature of Correlation Perception in Scatterplots},
  author = {Rensink, Ronald A.},
  year = {2017},
  journal = {Psychonomic Bulletin \& Review},
  volume = {24},
  number = {3},
  pages = {776--797},
  issn = {1069-9384},
  doi = {10.3758/s13423-016-1174-7},
  urldate = {2021-10-20},
  abstract = {For scatterplots with gaussian distributions of dots, the perception of Pearson correlation r can be described by two simple laws: a linear one for discrimination, and a logarithmic one for perceived magnitude (Rensink \& Baldridge, ). The underlying perceptual mechanisms, however, remain poorly understood. To cast light on these, four different distributions of datapoints were examined. The first had 100 points with equal variance in both dimensions. Consistent with earlier results, just noticeable difference (JND) was a linear function of the distance away from r = 1, and the magnitude of perceived correlation a logarithmic function of this quantity. In addition, these laws were linked, with the intercept of the JND line being the inverse of the bias in perceived magnitude. Three other conditions were also examined: a dot cloud with 25 points, a horizontal compression of the cloud, and a cloud with a uniform distribution of dots. Performance was found to be similar in all conditions. The generality and form of these laws suggest that what underlies correlation perception is not a geometric structure such as the shape of the dot cloud, but the shape of the probability distribution of the dots, likely inferred via a form of ensemble coding. It is suggested that this reflects the ability of observers to perceive the information entropy in an image, with this quantity used as a proxy for Pearson correlation.},
  pmcid = {PMC5486871},
  pmid = {27785683},
  file = {C:\Users\mbch4gs2\Zotero\storage\5P2V5N7A\Rensink - 2017 - The nature of correlation perception in scatterplo.pdf}
}

@article{rensink_2022,
  title = {Visual Features as Carriers of Abstract Quantitative Information},
  author = {Rensink, Ronald},
  year = {2022},
  month = jan,
  journal = {Journal of Experimental Psychology General},
  volume = {151},
  number = {8},
  pages = {1793--1820},
  doi = {10.1037/xge0001165},
  abstract = {Four experiments investigated the extent to which abstract quantitative information can be conveyed by basic visual features. This was done by asking observers to estimate and discriminate Pearson correlation in graphical representations where the first data dimension of each element was encoded by its horizontal position, and the second by the value of one of its visual features; perceiving correlation then requires combining the information in the two encodings via a common abstract representation. Four visual features were examined: luminance, color, orientation, and size. All were able to support the perception of correlation. Indeed, despite the strikingly different appearances of the associated stimuli, all gave rise to performance that was much the same: Just noticeable difference was a linear function of distance from complete correlation, and estimated correlation a logarithmic function of this distance. Performance differed only with regard to the level of noise in the feature, with these values compatible with estimates of channel capacity encountered in classic experiments on absolute perceptual magnitudes. These results suggest that quantitative information can be conveyed by visual features that are abstracted at relatively low levels of visual processing, with little representation of the original sensory property. It is proposed that this is achieved via an abstract parameter space in which the values in each perceptual dimension are normalized to have the same means and variances, with perceived correlation based on the shape of the joint probability density function of the resultant elements. (PsycInfo Database Record (c) 2022 APA, all rights reserved).},
  file = {C:\Users\mbch4gs2\Zotero\storage\PTIUISP2\Rensink - 2022 - Visual features as carriers of abstract quantitati.pdf}
}

@article{romero_2019,
  title = {Philosophy of Science and the Replicability Crisis},
  author = {Romero, Felipe},
  year = {2019},
  journal = {Philosophy Compass},
  volume = {14},
  number = {11},
  pages = {e12633},
  issn = {1747-9991},
  doi = {10.1111/phc3.12633},
  urldate = {2024-10-10},
  abstract = {Replicability is widely taken to ground the epistemic authority of science. However, in recent years, important published findings in the social, behavioral, and biomedical sciences have failed to replicate, suggesting that these fields are facing a ``replicability crisis.'' For philosophers, the crisis should not be taken as bad news but as an opportunity to do work on several fronts, including conceptual analysis, history and philosophy of science, research ethics, and social epistemology. This article introduces philosophers to these discussions. First, I discuss precedents and evidence for the crisis. Second, I discuss methodological, statistical, and social-structural factors that have contributed to the crisis. Third, I focus on the philosophical issues raised by the crisis. Finally, I discuss several proposals for solutions and highlight the gaps that philosophers could focus on.},
  copyright = {{\copyright} 2019 The Author. Philosophy Compass published by John Wiley \& Sons Ltd},
  langid = {english},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\JXC5KV5A\\Romero - 2019 - Philosophy of science and the replicability crisis.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\7HIC9J9E\\phc3.html}
}

@article{samuel_2024,
  title = {Computational Reproducibility of {{Jupyter}} Notebooks from Biomedical Publications},
  author = {Samuel, Sheeba and Mietchen, Daniel},
  year = {2024},
  month = jan,
  journal = {GigaScience},
  volume = {13},
  pages = {giad113},
  issn = {2047-217X},
  doi = {10.1093/gigascience/giad113},
  urldate = {2024-10-09},
  abstract = {Jupyter notebooks facilitate the bundling of executable code with its documentation and output in one interactive environment, and they represent a popular mechanism to document and share computational workflows, including for research publications. The reproducibility of computational aspects of research is a key component of scientific reproducibility but has not yet been assessed at scale for Jupyter notebooks associated with biomedical publications.We address computational reproducibility at 2 levels: (i) using fully automated workflows, we analyzed the computational reproducibility of Jupyter notebooks associated with publications indexed in the biomedical literature repository PubMed Central. We identified such notebooks by mining the article's full text, trying to locate them on GitHub, and attempting to rerun them in an environment as close to the original as possible. We documented reproduction success and exceptions and explored relationships between notebook reproducibility and variables related to the notebooks or publications. (ii) This study represents a reproducibility attempt in and of itself, using essentially the same methodology twice on PubMed Central over the course of 2 years, during which the corpus of Jupyter notebooks from articles indexed in PubMed Central has grown in a highly dynamic fashion.Out of 27,271 Jupyter notebooks from 2,660 GitHub repositories associated with 3,467 publications, 22,578 notebooks were written in Python, including 15,817 that had their dependencies declared in standard requirement files and that we attempted to rerun automatically. For 10,388 of these, all declared dependencies could be installed successfully, and we reran them to assess reproducibility. Of these, 1,203 notebooks ran through without any errors, including 879 that produced results identical to those reported in the original notebook and 324 for which our results differed from the originally reported ones. Running the other notebooks resulted in exceptions.We zoom in on common problems and practices, highlight trends, and discuss potential improvements to Jupyter-related workflows associated with biomedical publications.},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\ED7ZQDPR\\Samuel and Mietchen - 2024 - Computational reproducibility of Jupyter notebooks from biomedical publications.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\BD84WRIK\\7516267.html}
}

@article{saunders_2008,
  title = {Research Ethics and Lessons from {{Hwanggate}}: What Can We Learn from the {{Korean}} Cloning Fraud?},
  shorttitle = {Research Ethics and Lessons from {{Hwanggate}}},
  author = {Saunders, R. and Savulescu, J.},
  year = {2008},
  month = mar,
  journal = {Journal of Medical Ethics},
  volume = {34},
  number = {3},
  pages = {214--221},
  issn = {1473-4257},
  doi = {10.1136/jme.2007.023721},
  abstract = {In this review of the Korean cloning scandal involving Woo-Suk Hwang, the nature of the disaster is documented and reasons why it occurred are suggested. The general problems it raises for scientific research are highlighted and six possible ways of improving practice are offered in the light of this case: (1) better education of science students; (2) independent monitoring and validation; (3) guidelines for tissue donation for research; (4) fostering of debate about ethically contentious research in science journals; (5) development of an international code of ethical research practice; (6) fostering of public involvement in ethical review and debate through the web.},
  langid = {english},
  pmid = {18316467},
  keywords = {Animals,Animals Genetically Modified,Cattle,Cloning Organism,Dogs,Embryonic Stem Cells,Ethics Research,Female,Humans,Informed Consent,Korea,Oocyte Donation,Scientific Misconduct,Swine}
}

@article{schielzeth_2020,
  title = {Robustness of Linear Mixed-Effects Models to Violations of Distributional Assumptions},
  author = {Schielzeth, Holger and Dingemanse, Niels J. and Nakagawa, Shinichi and Westneat, David F. and Allegue, Hassen and Teplitsky, C{\'e}line and R{\'e}ale, Denis and Dochtermann, Ned A. and Garamszegi, L{\'a}szl{\'o} Zsolt and {Araya-Ajoy}, Yimen G.},
  year = {2020},
  journal = {Methods in Ecology and Evolution},
  volume = {11},
  number = {9},
  pages = {1141--1152},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.13434},
  urldate = {2023-11-29},
  abstract = {Linear mixed-effects models are powerful tools for analysing complex datasets with repeated or clustered observations, a common data structure in ecology and evolution. Mixed-effects models involve complex fitting procedures and make several assumptions, in particular about the distribution of residual and random effects. Violations of these assumptions are common in real datasets, yet it is not always clear how much these violations matter to accurate and unbiased estimation. Here we address the consequences of violations in distributional assumptions and the impact of missing random effect components on model estimates. In particular, we evaluate the effects of skewed, bimodal and heteroscedastic random effect and residual variances, of missing random effect terms and of correlated fixed effect predictors. We focus on bias and prediction error on estimates of fixed and random effects. Model estimates were usually robust to violations of assumptions, with the exception of slight upward biases in estimates of random effect variance if the generating distribution was bimodal but was modelled by Gaussian error distributions. Further, estimates for (random effect) components that violated distributional assumptions became less precise but remained unbiased. However, this particular problem did not affect other parameters of the model. The same pattern was found for strongly correlated fixed effects, which led to imprecise, but unbiased estimates, with uncertainty estimates reflecting imprecision. Unmodelled sources of random effect variance had predictable effects on variance component estimates. The pattern is best viewed as a cascade of hierarchical grouping factors. Variances trickle down the hierarchy such that missing higher-level random effect variances pool at lower levels and missing lower-level and crossed random effect variances manifest as residual variance. Overall, our results show remarkable robustness of mixed-effects models that should allow researchers to use mixed-effects models even if the distributional assumptions are objectively violated. However, this does not free researchers from careful evaluation of the model. Estimates that are based on data that show clear violations of key assumptions should be treated with caution because individual datasets might give highly imprecise estimates, even if they will be unbiased on average across datasets.},
  langid = {english},
  keywords = {biostatistics,correlated predictors,distributional assumptions,linear mixed-effects models,missing random effects,statistical quantification of individual differences (SQuID)},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\3ETINHH6\\Schielzeth et al. - 2020 - Robustness of linear mixed-effects models to viola.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\2D4QYXJB\\2041-210X.html}
}

@article{schuster_2024,
  title = {``{{Being Simple}} on {{Complex Issues}}'' -- {{Accounts}} on {{Visual Data Communication About Climate Change}}},
  author = {Schuster, Regina and Gregory, Kathleen and M{\"o}ller, Torsten and Koesten, Laura},
  year = {2024},
  month = sep,
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {30},
  number = {9},
  pages = {6598--6611},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2024.3352282},
  urldate = {2024-10-22},
  abstract = {Data visualizations play a critical role in both communicating scientific evidence about climate change and in stimulating engagement and action. To investigate how visualizations can be better utilized to communicate the complexities of climate change to different audiences, we conducted interviews with 17 experts in the fields of climate change, data visualization, and science communication, as well as with 12 laypersons. Besides questions about climate change communication and various aspects of data visualizations, we also asked participants to share what they think is the main takeaway message for two exemplary climate change data visualizations. Through a thematic analysis, we observe differences regarding the included contents, the length and abstraction of messages, and the sensemaking process between and among the participant groups. On average, experts formulated shorter and more abstract messages, often referring to higher-level conclusions rather than specific details. We use our findings to reflect on design decisions for creating more effective visualizations, particularly in news media sources geared toward lay audiences. We hereby discuss the adaption of contents according to the needs of the audience, the trade-off between simplification and accuracy, as well as techniques to make a visualization attractive.},
  keywords = {climate change,Climate change,Communication systems,Data analysis,Data visualization,Decision making,design decisions,experts,Interviews,laypeople,Professional communication,Scientific publishing,sensemaking,Surveys,takeaway messages,Thermal analysis,Uncertain systems,uncertainty,understandability},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\3XZ7RITM\\Schuster et al. - 2024 - Being Simple on Complex Issues  Accounts on Visual Data Communication About Climate Change.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\BZPQE9YI\\10414428.html}
}

@article{simmons_2021,
  title = {Pre-Registration: {{Why}} and {{How}}},
  shorttitle = {Pre-Registration},
  author = {P. Simmons, Joseph and D. Nelson, Leif and Simonsohn, Uri},
  year = {2021},
  journal = {Journal of Consumer Psychology},
  volume = {31},
  number = {1},
  pages = {151--162},
  issn = {1532-7663},
  doi = {10.1002/jcpy.1208},
  urldate = {2024-10-10},
  abstract = {In this article, we (1) discuss the reasons why pre-registration is a good idea, both for the field and individual researchers, (2) respond to arguments against pre-registration, (3) describe how to best write and review a pre-registration, and (4) comment on pre-registration's rapidly accelerating popularity. Along the way, we describe the (big) problem that pre-registration can solve (i.e., false positives caused by p-hacking), while also offering viable solutions to the problems that pre-registration cannot solve (e.g., hidden confounds or fraud). Pre-registration does not guarantee that every published finding will be true, but without it you can safely bet that many more will be false. It is time for our field to embrace pre-registration, while taking steps to ensure that it is done right.},
  langid = {english},
  keywords = {Open Science,P-Hacking.,Research Integrity,Research Transparency},
  file = {C:\Users\mbch4gs2\Zotero\storage\XG6NCRRF\jcpy.html}
}

@incollection{singmann_2019,
  title = {An Introduction to Mixed Models for Experimental Psychology},
  booktitle = {New Methods in Cognitive Psychology},
  author = {Singmann, Henrik and Kellen, David},
  year = {2019},
  pages = {4--31},
  publisher = {Routledge}
}

@article{stone_2008,
  title = {Alpha, Contrast and the Perception of Visual Metadata},
  author = {Stone, Maureen and Bartram, Lyn},
  year = {2008},
  journal = {Color and Imaging Conference},
  volume = {16},
  number = {355-355},
  pages = {5},
  abstract = {Visual elements such as grids, labels, and contour lines act as ``reference structures'' or ``visual metadata'' that support the primary information being presented. Such structures need to be usefully visible, but not so obtrusive that they clutter the presentation. Our goal is to determine the physical, perceptual and cognitive characteristics of such structures, ideally in a way that enables their automatic computation. We present the result of a set of experiments to determine effective display ranges, described in terms of transparency (alpha), for thin rectangular grids over scatterplot data. These show that an effective range can be defined in terms of alpha. In an effort to create a display-independent set of metrics, we analyze these results in terms of luminance contrast, with mixed results. We conclude that the appearance of transparency is an important aspect of subtle visualization.},
  langid = {english},
  file = {C:\Users\mbch4gs2\Zotero\storage\N5WPGYT3\Stone - Alpha, contrast and the perception of visual metad.pdf}
}

@article{strahan_1978,
  title = {Underestimating {{Correlation}} from {{Scatterplots}}},
  author = {Strahan, Robert F. and Hansen, Chris J.},
  year = {1978},
  month = oct,
  journal = {Applied Psychological Measurement},
  volume = {2},
  number = {4},
  pages = {543--550},
  publisher = {SAGE Publications Inc},
  issn = {0146-6216},
  doi = {10.1177/014662167800200409},
  urldate = {2022-06-29},
  abstract = {Eighty subjects estimated the correlation coeffi cient, r, for each of 13 computer-printed scatter plots. Making judgments were 46 students in a graduate-level statistics course and 34 faculty and graduate students in a department of psychology. The actual correlation values ranged from .010 to .995, with 200 observations in each scatterplot and with the order of scatterplot presentation ran domized. As predicted, subjects underestimated the degree of actual correlation. Also as predicted, but with substantial moderation by a method-of-presen tation factor, this underestimation was most pro nounced in the middle of the correlational range?between the 0 and 1 extremes. Though per ception of correlation was shown not to be veridical (i.e., in terms of r), little support was given one al ternative view?its being in terms of r 2.},
  file = {C:\Users\mbch4gs2\Zotero\storage\DQMPITM3\Strahan and Hansen - 1978 - Underestimating Correlation from Scatterplots.pdf}
}

@article{strain_2023,
  title = {The {{Effects}} of {{Contrast}} on {{Correlation Perception}} in {{Scatterplots}}},
  author = {Strain, Gabriel and Stewart, Andrew J. and Warren, Paul and Jay, Caroline},
  year = {2023},
  month = aug,
  journal = {International Journal of Human-Computer Studies},
  volume = {176},
  pages = {103040},
  issn = {1071-5819},
  doi = {10.1016/j.ijhcs.2023.103040},
  urldate = {2023-04-11},
  abstract = {Scatterplots are common data visualizations that can be used to communicate a range of ideas, the most intensively studied being the correlation between two variables. Despite their ubiquity, people typically do not perceive correlations between variables accurately from scatterplots, tending to underestimate the strength of the relationship displayed. Here we describe a two-experiment study in which we adjust the visual contrast of scatterplot points, and demonstrate a systematic approach to altering the bias. We find evidence that lowering the total visual contrast in a plot leads to increased bias in correlation estimates and show that decreasing the salience of points as a function of their distance from the regression line, by lowering their contrast, can facilitate more accurate correlation perception. We discuss the implications of these findings for visualization design, and provide a framework for online, reproducible, and large-sample-size (N = 150 per experiment) testing of the design parameters of data visualizations.},
  langid = {english},
  keywords = {Correlation perception,Crowdsourced,Data visualization,Scatterplot},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\TGMNQWN3\\Strain et al. - 2023 - The Effects of Contrast on Correlation Perception .pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\DBRLAN7I\\S1071581923000496.html}
}

@inproceedings{strain_2023b,
  title = {Adjusting {{Point Size}} to {{Facilitate More Accurate Correlation Perception}} in {{Scatterplots}}},
  booktitle = {2023 {{IEEE Vis X Vision}}},
  author = {Strain, Gabriel and Stewart, Andrew J. and Warren, Paul and Jay, Caroline},
  year = {2023},
  month = oct,
  pages = {1--5},
  publisher = {IEEE},
  address = {Melbourne, Australia},
  doi = {10.1109/VisXVision60716.2023.00006},
  urldate = {2024-02-15},
  abstract = {Viewers consistently underestimate correlation in positively correlated scatterplots. We use a novel data point size manipulation to correct for this bias. In a high-powered and fully reproducible study, we demonstrate that decreasing the size of a point on a scatterplot as a function of its distance from the regression line is able to correct for a systematic perceptual bias long present in the literature. We recommend the implementation of our technique when designing scatterplots that aim to communicate positive correlations.},
  isbn = {979-8-3503-2984-1},
  langid = {english},
  keywords = {Correlation,Empirical studies in HCI,Empirical studies in visualization,Human computer interaction,Human-centered computing,Human-centered computing-Human computer interaction (HCI),Systematics,Visualization},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\TZCCRWMX\\Strain et al. - 2023 - Adjusting Point Size to Facilitate More Accurate C.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\AYEELKVC\\10350485.html}
}

@inproceedings{strain_2024,
  title = {Effects of {{Point Size}} and {{Opacity Adjustments}} in {{Scatterplots}}},
  booktitle = {Proceedings of the {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Strain, Gabriel and Stewart, Andrew J. and Warren, Paul A. and Jay, Caroline},
  year = {2024},
  month = may,
  series = {{{CHI}} '24},
  pages = {1--13},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3613904.3642127},
  urldate = {2024-05-29},
  abstract = {Systematically changing the size and opacity of points on scatterplots can be used to induce more accurate perceptions of correlation by viewers. Evidence points to the mechanisms behind these effects being similar, so one may expect their combination to be additive regarding their effects on correlation estimation. We present a fully-reproducible study in which we combine techniques for influencing correlation perception to show that in reality, effects of changing point size and opacity interact in a non-additive fashion. We show that there is a great deal of scope for using visual features to change viewers' perceptions of data visualizations. Additionally, we use our results to further interrogate the perceptual mechanisms at play when changing point size and opacity in scatterplots.},
  isbn = {979-8-4007-0330-0},
  keywords = {correlation,crowdsourced,perception,scatterplot},
  file = {C:\Users\mbch4gs2\Zotero\storage\IGSEXHSG\Strain et al. - 2024 - Effects of Point Size and Opacity Adjustments in S.pdf}
}

@article{tamuhla_2023,
  title = {Multiple Modes of Data Sharing Can Facilitate Secondary Use of Sensitive Health Data for Research},
  author = {Tamuhla, Tsaone and Lulamba, Eddie T and Mutemaringa, Themba and Tiffin, Nicki},
  year = {2023},
  month = oct,
  journal = {BMJ Global Health},
  volume = {8},
  number = {10},
  pages = {e013092},
  issn = {2059-7908},
  doi = {10.1136/bmjgh-2023-013092},
  urldate = {2024-10-10},
  abstract = {Evidence-based healthcare relies on health data from diverse sources to inform decision-making across different domains, including disease prevention, aetiology, diagnostics, therapeutics and prognosis. Increasing volumes of highly granular data provide opportunities to leverage the evidence base, with growing recognition that health data are highly sensitive and onward research use may create privacy issues for individuals providing data. Concerns are heightened for data without explicit informed consent for secondary research use. Additionally, researchers---especially from under-resourced environments and the global South---may wish to participate in onward analysis of resources they collected or retain oversight of onward use to ensure ethical constraints are respected. Different data-sharing approaches may be adopted according to data sensitivity and secondary use restrictions, moving beyond the traditional Open Access model of unidirectional data transfer from generator to secondary user. We describe collaborative data sharing, facilitating research by combining datasets and undertaking meta-analysis involving collaborating partners; federated data analysis, where partners undertake synchronous, harmonised analyses on their independent datasets and then combine their results in a coauthored report, and trusted research environments where data are analysed in a controlled environment and only aggregate results are exported. We review how deidentification and anonymisation methods, including data perturbation, can reduce risks specifically associated with health data secondary use. In addition, we present an innovative modularised approach for building data sharing agreements incorporating a more nuanced approach to data sharing to protect privacy, and provide a framework for building the agreements for each of these data-sharing scenarios.},
  pmcid = {PMC10565310},
  pmid = {37802544},
  file = {C:\Users\mbch4gs2\Zotero\storage\85F78NES\Tamuhla et al. - 2023 - Multiple modes of data sharing can facilitate secondary use of sensitive health data for research.pdf}
}

@inproceedings{tominskiInformationVisualizationClimate2011,
  title = {Information {{Visualization}} in {{Climate Research}}},
  booktitle = {2011 15th {{International Conference}} on {{Information Visualisation}}},
  author = {Tominski, Christian and Donges, Jonathan F. and Nocke, Thomas},
  year = {2011},
  month = jul,
  pages = {298--305},
  publisher = {IEEE},
  address = {London, United Kingdom},
  doi = {10.1109/IV.2011.12},
  urldate = {2024-10-22},
  abstract = {Much of the work conducted in climate research involves large and heterogeneous datasets with spatial and temporal references. This makes climate research an interesting application area for visualization. However, the application of interactive visual methods to assist in gaining insight into climate data is still hampered for climate research scientists, who are usually not visualization experts.},
  isbn = {978-1-4577-0868-8},
  langid = {english},
  file = {C:\Users\mbch4gs2\Zotero\storage\MIMXU33L\Tominski et al. - 2011 - Information Visualization in Climate Research.pdf}
}

@article{trisovic_2022,
  title = {A Large-Scale Study on Research Code Quality and Execution},
  author = {Trisovic, Ana and Lau, Matthew K. and Pasquier, Thomas and Crosas, Merc{\`e}},
  year = {2022},
  month = feb,
  journal = {Scientific Data},
  volume = {9},
  number = {1},
  pages = {60},
  publisher = {Nature Publishing Group},
  issn = {2052-4463},
  doi = {10.1038/s41597-022-01143-6},
  urldate = {2024-10-09},
  abstract = {This article presents a study on the quality and execution of research code from publicly-available replication datasets at the Harvard Dataverse repository. Research code is typically created by a group of scientists and published together with academic papers to facilitate research transparency and reproducibility. For this study, we define ten questions to address aspects impacting research reproducibility and reuse. First, we retrieve and analyze more than 2000 replication datasets with over 9000 unique R files published from 2010 to 2020. Second, we execute the code in a clean runtime environment to assess its ease of reuse. Common coding errors were identified, and some of them were solved with automatic code cleaning to aid code execution. We find that 74\% of R files failed to complete without error in the initial execution, while 56\% failed when code cleaning was applied, showing that many errors can be prevented with good coding practices. We also analyze the replication datasets from journals' collections and discuss the impact of the journal policy strictness on the code re-execution rate. Finally, based on our results, we propose a set of recommendations for code dissemination aimed at researchers, journals, and repositories.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Information technology,Research data,Software},
  file = {C:\Users\mbch4gs2\Zotero\storage\YAWPBCQQ\Trisovic et al. - 2022 - A large-scale study on research code quality and execution.pdf}
}

@article{varshney_2013,
  title = {Why Do We Perceive Logarithmically?},
  author = {Varshney, Lav R. and Sun, John Z.},
  year = {2013},
  journal = {Significance},
  volume = {10},
  number = {1},
  pages = {28--31},
  issn = {1740-9713},
  doi = {10.1111/j.1740-9713.2013.00636.x},
  urldate = {2022-09-02},
  abstract = {Why do small children place 3 halfway between 1 and 10? Why do two light bulbs not seem twice as bright as one? Why do we perceive so many things logarithmically? Lav R. Varshney and John Z. Sun can explain it, through evolution, the statistics of nature -- and reducing error.},
  langid = {english},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\4F3KIGIE\\Varshney and Sun - 2013 - Why do we perceive logarithmically.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\W3TTNKJ6\\j.1740-9713.2013.00636.html}
}

@article{wehrhahn_1990,
  title = {How Vernier Acuity Depends on Contrast},
  author = {Wehrhahn, C. and Westheimer, G.},
  year = {1990},
  month = may,
  journal = {Experimental Brain Research},
  volume = {80},
  number = {3},
  pages = {618--620},
  issn = {0014-4819, 1432-1106},
  doi = {10.1007/BF00228001},
  urldate = {2022-11-02},
  abstract = {Vernier a c u i t y was m e a s u r e d b y finding the just discriminable offset for an edge separating fields of different luminances. The contrast of this stimulus is easily specified b y the f o r m u l a c = (Lstim- Lsur)(Lstim 4-L{\textasciitilde}ur). Vernier thresholds are about 4-5 sec of arc for contrasts 0.22 and higher, but increase exponentially with decreasing contrast (Fig. 1). By c o m p a r i s o n , the presence of the stimulus could be detected at a contrast of 0.016. The possible role of the magnocellular and parvocellular pathways in carrying the input signals to the fine localization process is discussed.},
  langid = {english},
  keywords = {Contrast sensitivity,Hyperacuity,Magno- and parvocellular pathway,Vernier acuity},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\7DMNYQVG\\Wehrhahn and Westheimer - 1990 - How vernier acuity depends on contrast.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\L2JM6LAM\\Wehrhahn and Westheimer - 1990 - How vernier acuity depends on contrast.pdf}
}

@article{wei_2020,
  title = {Evaluating {{Perceptual Bias During Geometric Scaling}} of {{Scatterplots}}},
  author = {Wei, Yating and Mei, Honghui and Zhao, Ying and Zhou, Shuyue and Lin, Bingru and Jiang, Haojing and Chen, Wei},
  year = {2020},
  month = jan,
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {26},
  number = {1},
  eprint = {1908.00403},
  pages = {321--331},
  issn = {1077-2626, 1941-0506, 2160-9306},
  doi = {10.1109/TVCG.2019.2934208},
  urldate = {2020-12-03},
  abstract = {Scatterplots are frequently scaled to fit display areas in multi-view and multi-device data analysis environments. A common method used for scaling is to enlarge or shrink the entire scatterplot together with the inside points synchronously and proportionally. This process is called geometric scaling. However, geometric scaling of scatterplots may cause a perceptual bias, that is, the perceived and physical values of visual features may be dissociated with respect to geometric scaling. For example, if a scatterplot is projected from a laptop to a large projector screen, then observers may feel that the scatterplot shown on the projector has fewer points than that viewed on the laptop. This paper presents an evaluation study on the perceptual bias of visual features in scatterplots caused by geometric scaling. The study focuses on three fundamental visual features (i.e., numerosity, correlation, and cluster separation) and three hypotheses that are formulated on the basis of our experience. We carefully design three controlled experiments by using well-prepared synthetic data and recruit participants to complete the experiments on the basis of their subjective experience. With a detailed analysis of the experimental results, we obtain a set of instructive findings. First, geometric scaling causes a bias that has a linear relationship with the scale ratio. Second, no significant difference exists between the biases measured from normally and uniformly distributed scatterplots. Third, changing the point radius can correct the bias to a certain extent. These findings can be used to inspire the design decisions of scatterplots in various scenarios.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Human-Computer Interaction},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\36T233EX\\Wei et al. - 2020 - Evaluating Perceptual Bias During Geometric Scalin.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\IN5U2BVZ\\1908.html}
}

@book{wickham_2016,
  title = {Ggplot2: {{Elegant Graphics}} for {{Data Analysis}}},
  author = {Wickham, Hadley},
  year = {2016},
  publisher = {Springer-Verlag New York},
  urldate = {2022-09-14},
  isbn = {978-3-319-24277-4},
  langid = {english},
  file = {C:\Users\mbch4gs2\Zotero\storage\3IA3HC9Z\978-3-319-24277-4.html}
}

@article{wilkinson_2016,
  title = {The {{FAIR Guiding Principles}} for Scientific Data Management and Stewardship},
  author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and Santos, Luiz Bonino da Silva and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Merc{\`e} and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and {Gonzalez-Beltran}, Alejandra and Gray, Alasdair J. G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and 't Hoen, Peter A. C. and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and {Rocca-Serra}, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
  year = {2016},
  journal = {Scientific Data},
  volume = {3},
  publisher = {Nature Publishing Group},
  doi = {10.1038/sdata.2016.18},
  urldate = {2024-10-10},
  abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders---representing academia, industry, funding agencies, and scholarly publishers---have come together to design and jointly ...},
  langid = {english},
  pmid = {26978244},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\IU5RXNY2\\Wilkinson et al. - 2016 - The FAIR Guiding Principles for scientific data management and stewardship.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\4XEE55PA\\PMC4792175.html}
}

@book{xie_2015,
  title = {Dynamic Documents with {{R}} and Knitr},
  author = {Xie, Yihui},
  year = {2015},
  edition = {2},
  publisher = {{Chapman and Hall/CRC}},
  address = {Boca Raton, Florida}
}

@book{xie_2020,
  title = {R Markdown Cookbook},
  author = {Xie, Yihui and Dervieux, Christophe and Riederer, Emily},
  year = {2020},
  publisher = {{Chapman and Hall/CRC}},
  address = {Boca Raton, Florida},
  isbn = {978-0-367-56383-7}
}

@article{yang_2019,
  title = {Correlation {{Judgment}} and {{Visualization Features}}: {{A Comparative Study}}},
  shorttitle = {Correlation {{Judgment}} and {{Visualization Features}}},
  author = {Yang, F. and Harrison, L. T. and Rensink, R. A. and Franconeri, S. L. and Chang, R.},
  year = {2019},
  month = mar,
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {25},
  number = {3},
  pages = {1474--1488},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2018.2810918},
  abstract = {Recent visualization research efforts have incorporated experimental techniques and perceptual models from the vision science community. Perceptual laws such as Weber's law, for example, have been used to model the perception of correlation in scatterplots. While this thread of research has progressively refined the modeling of the perception of correlation in scatterplots, it remains unclear as to why such perception can be modeled using relatively simple functions, e.g., linear and log-linear. In this paper, we investigate a longstanding hypothesis that people use visual features in a chart as a proxy for statistical measures like correlation. For a given scatterplot, we extract 49 candidate visual features and evaluate which best align with existing models and participant judgments. The results support the hypothesis that people attend to a small number of visual features when discriminating correlation in scatterplots. We discuss how this result may account for prior conflicting findings, and how visual features provide a baseline for future model-based approaches in visualization evaluation and design.},
  keywords = {candidate visual features,Computational modeling,Computer Graphics,Correlation,correlation judgment,Data models,data visualisation,Data visualization,evaluation/methodology,feature extraction,Feature extraction,Female,Humans,Information visualization,Judgment,model-based approaches,Models Statistical,perception and psychophysics,perceptual laws,perceptual models,power law,Psychology,Psychophysics,scatterplots,vision science community,visual perception,Visual Perception,Visualization,visualization evaluation,visualization features,Weber's law},
  file = {C\:\\Users\\mbch4gs2\\Zotero\\storage\\BRQKUR29\\Yang et al. - 2019 - Correlation Judgment and Visualization Features A.pdf;C\:\\Users\\mbch4gs2\\Zotero\\storage\\UISL6ES3\\8305493.html}
}

@inproceedings{zuffi_2007,
  title = {Human {{Computer Interaction}}: {{Legibility}} and {{Contrast}}},
  shorttitle = {Human {{Computer Interaction}}},
  booktitle = {14th {{International Conference}} on {{Image Analysis}} and {{Processing}} ({{ICIAP}} 2007)},
  author = {Zuffi, Silvia and Brambilla, Carla and Beretta, Giordano and Scala, Paolo},
  year = {2007},
  month = sep,
  pages = {241--246},
  doi = {10.1109/ICIAP.2007.4362786},
  abstract = {In human computer interaction readability of textual information is one of the foremost requirements for displays designed to provide visual information. In this context it is of main interest to identify the design attributes that influence readability, and investigate their relationship with measures of ease of reading. In this paper we present results from a readability experiment focused on text contrast that we performed on the Web. Our analysis indicate that light text on dark background is more difficult to read, and that the minimum luminance contrast between foreground and background color, in terms of CIELAB lightness difference, should be about 27 units.},
  keywords = {Character recognition,Color,Computer displays,Human computer interaction,Laboratories,Psychology,Testing,Text recognition,Visual system,Web sites},
  file = {C:\Users\mbch4gs2\Zotero\storage\PYI6YJSD\Zuffi et al. - 2007 - Human Computer Interaction Legibility and Contras.pdf}
}
