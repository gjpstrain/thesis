@article{lam_2012,
  title = {Empirical {{Studies}} in {{Information Visualization}}: {{Seven Scenarios}}},
  shorttitle = {Empirical {{Studies}} in {{Information Visualization}}},
  author = {Lam, H. and Bertini, E. and Isenberg, P. and Plaisant, C. and Carpendale, S.},
  year = {2012},
  month = sep,
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {18},
  number = {9},
  pages = {1520--1536},
  issn = {1077-2626},
  doi = {10.1109/TVCG.2011.279},
  urldate = {2024-03-14},
  abstract = {We take a new, scenario-based look at evaluation in information visualization. Our seven scenarios, evaluating visual data analysis and reasoning, evaluating user performance, evaluating user experience, evaluating environments and work practices, evaluating communication through visualization, evaluating visualization algorithms, and evaluating collaborative data analysis were derived through an extensive literature review of over 800 visualization publications. These scenarios distinguish different study goals and types of research questions and are illustrated through example studies. Through this broad survey and the distillation of these scenarios, we make two contributions. One, we encapsulate the current practices in the information visualization research community and, two, we provide a different approach to reaching decisions about what might be the most effective evaluation of a given information visualization. Scenarios can be used to choose appropriate research questions and goals and the provided examples can be consulted for guidance on how to design one's own study.},
  langid = {english}
}
