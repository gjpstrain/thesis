---
title: "interactions_opacity_size"
output:
  format: 
    latex:
      
params:
  eval_models: false
  
knitr:
  opts_chunk: 
    cache_comments: false
    crop: true
    out-width: NA
    out-height: NA
    cache.path: "../thesis_cache/" 

execute: 
  echo: false
  warning: false
  message: false
  include: false         
---

```{r}
#| label: setup

# load packages

library(tidyverse)
library(MASS)
library(emmeans)
library(scales)
library(buildmer)
library(lme4)
library(kableExtra)
library(afex)
library(papaja)
library(broom.mixed)
library(insight)
library(qwraps2)
library(lmerTest)
library(tinylabels)
library(ggdist)
library(ggpubr)
library(geomtextpath)
library(conflicted)
library(formattable)
library(effectsize)
library(r2glmm)
library(DescTools)

# fix conflicts

conflicts_prefer(dplyr::select(), dplyr::filter(), lme4::lmer())

# define plotting labels now

labels_e4 <- c(A = "Typical Orientation Size\nTypical Orientation Opacity",
               B = "Inverted Orientation Size\nInverted Orientation Opacity",
               X = "Typical Orientation Size\nInverted Orientation Opacity",
               Y = "Inverted Orientation Size\nTypical Orientation Opacity")

labels_e4_regex <- c(
  "\\bA\\b" = "Typical Orientation Size Typical Orientation Opacity",
  "\\bB\\b" = "Inverted Orientation Size Inverted Orientation Opacity",
  "\\bX\\b" = "Typical Orientation Size Inverted Orientation Opacity",
  "\\bY\\b" = "Inverted Orientation Size\nTypical Orientation Opacity"
)

labels_all_exp <- c(additive_manipulation = "Size and Opacity Decay",
                    opacity_manipulated = "Opacity Decay",
                    size_manipulated = "Size Decay",
                    standard_plot = "Typical Scatterplot")


labels_power <- c(size_power = "Size\nPower",
                  opacity_power = "Opacity\nPower",
                  additive_power = "Size and Opacity\nCombined Power")
```

```{r}
#| label: load-data

exp4_anon <- read_csv("../data/exp_4_data.csv", guess_max = 17000) %>%
  mutate("expName" = recode(expName,
                            "size_and_opacity_exp" = "E4_interactions"))

source("../shared_functions.R")
```

```{r}
#| label: retrieve-cached-models-chap6

if (!params$eval_models){ lazyload_cache_dir("../thesis_cache/") }
```

```{r}
#| label: wrangle-data

## NB: With the exception of anonymization, data are provided as-is from 
## pavlovia (survey tool). Wrangling function *must* be run first to make
## the data set usable

# first do literacy

wrangle <- function(anon_file) {
  
  literacy <- anon_file %>%
    filter(!is.na(q5_slider.response)) %>%
    rowwise() %>%
    mutate(literacy = sum(c(q1_slider.response, 
                            q2_slider.response, 
                            q3_slider.response, 
                            q4_slider.response, 
                            q5_slider.response))) %>%
    select(participant,
           literacy)
  
# extract and process visual threshold testing
  
visual_thresholds <- anon_file %>%
    filter(!is.na(VT_with_labels)) %>%
    select(c("VT_with_labels",
             "participant",
             "VT_textbox2.text")) %>%
    mutate(VT_answer = str_replace(VT_with_labels,
                                   pattern = "vis_threshold_plots/",
                                   replacement = "")) %>%
    mutate(VT_answer = str_replace(VT_answer,
                                   pattern = "_VT.png",
                                   replacement = "")) %>%
    mutate(correct_VT = case_when(
      VT_answer == VT_textbox2.text ~ "y",
      VT_answer != VT_textbox2.text ~ "n",
      is.na(VT_answer) ~ "n", TRUE ~ as.character(VT_answer))) %>%
    group_by(participant) %>% 
    summarise(VT_no_correct = sum(correct_VT == "y")) %>%
    mutate(VT_perc_correct = (VT_no_correct/6)*100) %>%
    select("VT_perc_correct",
           "VT_no_correct",
           "participant")
  
# extract and process monitor and dot pitch information
# we assume standard 16:9 aspect ratio for monitors
  
monitor_information <- anon_file %>%
  mutate(height = dplyr::lead(height)) %>%
  mutate(res_height = res_width*0.5625,
         width = height*1.777,
         dot_pitch = ((sqrt(height^2 + width^2))/(sqrt(res_height^2 + res_width^2))) * 25.4) %>%
         select(c("dot_pitch",
                  "participant",
                  "res_width",
                  "width",
                  "height")) %>%
  na.omit()
  
# extract demographic information
# link slider response numbers to gender categories
  
demographics <- anon_file %>%
    filter(!is.na(gender_slider.response)) %>%
    mutate(gender_slider.response = recode(gender_slider.response,
                                         `1` = "F",
                                         `2` = "M",
                                         `3` = "NB")) %>%
  select(matches(c("participant",
                    "age_textbox.text",
                    "gender_slider.response")))

# split images column into item and condition columns
# additionally create "condition_abs" column
# this will be simpler to plot with later

anon_file <- anon_file %>%
  mutate(images = str_replace(images, pattern = "A", replacement = "-S-S")) %>%
  mutate(images = str_replace(images, pattern = "B", replacement = "-I-I")) %>%
  mutate(images = str_replace(images, pattern = "X", replacement = "-S-I")) %>%
  mutate(images = str_replace(images, pattern = "Y", replacement = "-I-S")) %>%
  separate(images, c("item",
                     "opacity",
                     "size"),
           sep = "-") %>%
  mutate(size = str_replace(size, pattern = ".png", replacement = "")) %>%
  mutate(condition_abs = case_when(
    opacity == "S" & size == "S" ~ "A",
    opacity == "I" & size == "I" ~ "B",
    opacity == "S" & size == "I" ~ "X",
    opacity == "I" & size == "S" ~ "Y",
    TRUE ~ "placeholder"
  ))

# select relevant columns
# select only experimental items
# add literacy data
# change data types where appropriate
# output this file with suffix 'tidy'

anon_file %>%
  select(c("participant",
            "item",
            "size",
            "opacity",
            "slider.response",
            "my_rs",
            "total_residuals",
            "unique_item_no",
            "session",
            "trials.thisN",
            "condition_abs")) %>%
  mutate(half = case_when(
    trials.thisN < 93 ~ "First",
    trials.thisN > 92 ~ "Second" )) %>% # used for training testing later on
  filter(unique_item_no < 181) %>%
  inner_join(literacy, by = "participant") %>%
  inner_join(demographics, by = "participant") %>%
  inner_join(monitor_information, by = "participant") %>%
  inner_join(visual_thresholds, by = "participant") %>%
  mutate(across(matches(c("item", "opacity", "size", "condition_abs")), as_factor)) %>%
  mutate(trials.thisN = as.integer(trials.thisN)) %>%
  mutate(difference = my_rs - slider.response) %>%
  select(-c("__participant")) %>%
  assign(paste0(unique(anon_file$expName), "_tidy"),
           value = ., envir = .GlobalEnv)
}

# use wrangle function on anonmyised data file 

wrangle(exp4_anon)

# set deviation coding for experimental model

contrasts(E4_interactions_tidy$size) <- matrix(c(.5, -.5))
contrasts(E4_interactions_tidy$opacity) <- matrix(c(.5, -.5))

# remove anon df from environment

rm(exp4_anon)

# extract age and gender data

extract_age(E4_interactions_tidy)

extract_gender(E4_interactions_tidy)

extract_literacy(E4_interactions_tidy)

# significance table function. This function is only used in this chapter, and 
# hence does not appear in the shared_functions.R file

make_sig_table <- function (model) {
  
  # buildmer class models need reassigned to lmer class for further use
  
  if (class(model) == "buildmer") model <- model@model
  
  # subset model summary to get list of fixed/interaction effects
  # then make this a data frame, rename columns, fix p value formatting
  
  table_df <- as.data.frame(summary(model)[10]) %>%
    rename("Estimate" = "coefficients.Estimate",
           "Standard Error" = "coefficients.Std..Error",
           "df" = "coefficients.df",
           "t-value" = "coefficients.t.value",
           "p" = "coefficients.Pr...t..") %>%
    mutate(p = scales::pvalue(p)) %>%
    rename("\\textit{p}" = "p")
  
  # get semi-partial r^2, rename rows so they match with sig table
  # take the last 3 rows corresponding to fixed effects and interaction term
  # remove first cell of r^2
  # reformat text for latex output
  
  r_squared <- r2beta(model, method = "nsj") %>%
    mutate("Effect" = recode(Effect,
                             "size" = "Size Decay",
                             "opacity" = "Opacity Decay",
                             "size:opacity" = "Size Decay x Opacity Decay")) %>%
    select(c("Effect", "Rsq")) %>%
    mutate(Rsq = round(Rsq, 3)) %>%
    mutate(Rsq = ifelse(row_number() == 1, "", Rsq)) %>%
    rename("R\\textsuperscript{2}" = "Rsq") 
    
  # tidy up row names
  
  rownames(table_df) <- c("(Intercept)",
                          "Size Decay",
                          "Opacity Decay",
                          "Size Decay x Opacity Decay")
  
  sig_and_squared <- cbind(table_df, r_squared) %>% select(-c("Effect")) 
  
  table <- kbl(sig_and_squared, booktabs = T, digits = c(2,3,2,2,2,2,3), escape = F)
  
  return(table)
}
```

# Abstract {#abstract-interactions}

\chap{chap:adjusting_opacity} and \chap{chap:adjusting_size} each provide evidence
for the effects of changing the opacities and sizes of scatterplot points
on people's performance on a correlation estimation task. It is clear from the
results of the experiments presented in those chapters, however, that the effects of
changing point opacity and size on correlation estimation in positively correlated
scatterplots are different, both with regards to the strength of the correction
provided and the shape of the estimation curve produced. Mechanistically, however,
point opacity and size may operate similarly by reducing the influence of more exterior
points in scatterplots. To further investigate these mechanisms, and in the interest of
providing a more complete description of the ways in which changing point opacity
and size can bias correlation estimation, I present a single experiment study combining the
point opacity and size manipulations from \chap{chap:adjusting_opacity} and \chap{chap:adjusting_size}.
In a condition where point opacity and size are reduced as a function of residual
magnitude, correlation estimation is significantly biased upwards, a finding
that suggests the effects of changing point opacity and size are not linearly additive.

# Introduction {#introduction-interactions}

The work presented in \chap{chap:adjusting_opacity} and \chap{chap:adjusting_size}
shows that point opacity and size adjustments can be used to bias perceptions of
correlation in positively correlated scatterplots. These findings are in opposition
to work finding both bias and variability in correlation perception to be
invariant to both uniform and irregular changes in point opacities and sizes
\cite{rensink_2012, rensink_2014}. Of course, when attempting to provide tools for
visualisation designers to design *better* visualisations, more options are preferable
to few. In this spirit, then, I endeavoured to answer the next big question;
what happens when point opacity and size manipulations are combined? Answering
this question would not only allow for a deeper exploration of the potential
mechanisms behind each decay function, but would further empower visualisation
designers with the knowledge of how altering point opacities and sizes might 
affect people's interpretations of the correlations displayed therein. In a
fully-reproducible, large-sample (N = 150) study, I show that combining point opacity
and size manipulations can produce more powerful effects on correlation estimation
than either manipulation in isolation. Additionally, I comment on the impact that the adjustment
of each visual feature may have on correlation estimation, and suggest future work
to tune the effects seen in \chap{chap:adjusting_opacity}, \chap{chap:adjusting_size},
and here.

# Related Work {#related-work-interactions}

Much of the related work presented here is covered in more detail in \chap{chap:related_work}
and in Sections \ref{related-work-adjusting-opacity} and \ref{related-work-adjusting-size}.
For the reader's convenience, and to properly contextualise the experimental methods
and findings in the present chapter, this related work is reproduced in brief here.

## Opacity and Contrast

Changing the opacities of points in scatterplots is standard practice when
visualising very large datasets to address overplotting \cite{matejka_2015}.
Figure \ref{fig-overplotting-examples} visualises how point opacity is often
reduced when large numbers of points are present to preserve individual point
discriminability. While work on the effects of point opacity on correlation perception
in scatterplots has taken place, it is often contradictory. Earlier work
found correlation perception invariant to changes in the opacities of points
\cite{rensink_2012, rensink_2014}, while the work I completed in \chap{chap:adjusting_opacity}
found clear, if small, effects. That work offered both point salience/perceptual
weighting and spatial uncertainty as potential drivers for the effects found.
Lower stimulus contrast, which for isolated stimuli is functionally identical to 
lower opacity, is associated with lower salience \cite{healey_2012}, can bias
judgements of mean point position \cite{hong_2022}, increases error in positional
judgements \cite{wehrhahn_1990}, and can result in greater uncertainty in speed
perception \cite{champion_2017}. Due to mechanistic accounts of both 
salience/perceptual weighting and spatial uncertainty predicting results in the
same direction regarding opacity adjustments, the work I conducted in
\chap{chap:adjusting_opacity} was unable to distinguish between
explanations rooted in point salience/perceptual weighting and spatial uncertainty
as drivers for the effect found.

Micallef et al. \cite{micallef_2017} found that "merging, dark dots"
support correlation estimation; despite only changing point opacity in a *uniform*
manner, the sheer number of points used in that study results
in scatterplots that appear similar to those that reduce opacity as a function
of residual error (see \chap{chap:adjusting_opacity}). That this technique has 
been shown to produce more accurate correlation estimates as compared to unadjusted
scatterplots may explain why the optimisation system employed in Micallef et 
al. \cite{micallef_2017} conferred benefits regarding correlation estimation.

## Point Size

Again, for discriminability reasons, scatterplots dealing with larger datasets
tend to have smaller individual points. Section \ref{point-size-chap5} explores
this, and related bubble charts, in greater detail. As with opacity, the work
exploring the effects of point size on correlation perception in scatterplots is
conflicted. Some finds correlation perception to be invariant to both global
and irregular changes in point opacity \cite{rensink_2012, rensink_2014}, while
the work presented in \chap{chap:adjusting_size} contradicts this, finding 
effects on correlation perception that go beyond that available through manipulation
only of point opacity.

While the mechanistic driver of the effects of point opacity on correlation
perception is unclear, the balance of evidence for point size points towards
a point salience/perceptual weighting account. There is evidence that larger 
stimulus size is associated with lower levels of spatial certainty \cite{alais_2004},
but higher levels of salience \cite{healey_2012}, results which are supported by evidence 
that reaction times are slower to smaller stimuli \cite{gramazio_2014, osaka_1976}.
The predicted effects of spatial certainty and salience on correlation perception
operate in the opposite direction to one another, lead to the conclusion in
\chap{chap:adjusting_size} that point salience is a more likely candidate mechanism.
In an investigation into perceptions of global means in scatterplots, it has been
found that perceptions are biased towards areas that contain larger points \cite{hong_2022}.
These findings form the theoretical basis behind the third hypothesis in the 
present work.

# Hypotheses {#hypotheses-interactions}

A single experiment is present in this chapter based on the effects of adjusting
point opacity and size on correlation estimation established in \chap{chap:adjusting_opacity}
and \chap{chap:adjusting_size}. Here, previously independently tested point opacity and size
manipulations are tested in both typical orientation (point opacity/size is 
reduced with residual magnitude) and inverted orientation (point opacity/size
is increased with residual magnitude). Throughout this chapter, referral is made
to *congruent* and *incongruent* conditions with respect to the combination of 
point opacity and size decay functions. *Congruent* conditions are those in which
point opacity and size decay act in the same direction (typical or inverted),
while for *incongruent* conditions, point opacity and size decay act against 
each other. Due to previous findings that non-linearly reducing point opacity 
or size as a function of residual magnitude can bias correlation estimates upwards,
and that increasing point opacity and size can further bias estimates downwards,
it is hypothesised that:

 - H1: an increased reduction in correlation estimation error will be observed
 when congruent typical orientation decay functions are used.
 - H2: the use of a congruent inverted function, such that point opacity and size
 are both increased with residual magnitude, will produce the least accurate
 estimates of correlation.
 
Owing to the finding from \chap{chap:adjusting_size} that point size is a stronger
channel for biasing correlation estimation than point opacity, it is also 
hypothesised that:

 - H3: there will be a significant difference in correlation estimates between
 the two incongruent orientation conditions.

# Method {#method-e4}

## Open Research {#open-research-chap6}

The experiment was conducted according to the principles of open and reproducible 
research \cite{ayris_2018}. All data and code for the original paper are maintained in a GitHub
repository [^1]. This repository also features an implementation of a Docker
container that enables the full recreation of the computational environment in which
the original paper was written. The experiment itself is hosted on GitLab [^2].
The hypotheses and analysis plans were pre-registered with the Open Science Framework (OSF)
[^3], and no deviations from them were made.

[^1]: https://github.com/gjpstrain/size_opacity_and_scatterplots
[^2]: https://gitlab.pavlovia.org/Strain/size_and_opacity_additive_exp
[^3]: https://osf.io/j32sk

## Stimuli {#stimuli-e4}

The creation of the stimuli in this experiment follows the same general principles
outline in Section \ref{creating-stimuli}, \chap{chap:gen_methods}. `ggplot2` 
(version 3.5.0) was used to create the stimuli. Again, equation
6.1 was used to map point residuals to opacity and size values:

\begin{equation}
  point_{size/opacity} = 1 - b^{residual}
\end{equation}

For the changes made to point size in this experiment, a constant of 0.2 was added
to each raw value, along with a scaling factor of 4; as in \chap{chap:adjusting_size},
these adjustments resulted in the smallest points having a width of 12 pixels on
a 1920x1080 pixel monitor, which is consistent with the point size used in 
\chap{chap:adjusting_opacity} and the minimum point size used in \chap{chap:adjusting_size}.
With regards to changing the opacities of points, an alpha = 0.2 floor was implemented,
as informal piloting indicated low levels of visibility when very small points were
especially transparent. In this experiment, point opacity or size manipulations in which a reduction with
residual magnitude takes place are referred to as *typical orientation*, while those
in which point opacity or size are increased with residual magnitude are referred
to as *inverted orientation*. Additionally, as the current experiment only examines
combinations of point opacity and size decay manipulations, the nature of these
combinations are classified. When both point size and opacity decay operate in
the same direction, that condition is referred to as *congruent*. When they operate
in opposition to each other, those conditions are referred to as *incongruent*.
Labelled examples of the stimuli used in this experiment can be viewed in 
@fig-exp4-examples-chap6.

```{r}
#| label: fig-exp4-examples-chap6
#| include: true
#| fig-cap: Examples of the stimuli used in experiment 4, demonstrated with an \textit{r} value of 0.6.
#| fig-asp: 0.275

examples_congruent <- ggarrange(plot_example_function(data_with_resid,
                                                      "Typical Orientation Size\nTypical Orientation Opacity",
                                                      (1-slopes$slope_0.25),
                                                      (1-slopes$slope_0.25),
                                                      6.25),
                                plot_example_function(data_with_resid,
                                                      "Inverted Orientation Size\nInverted Orientation Opacity",
                                                      (1-slopes$slope_inverted),
                                                      (1-slopes$slope_inverted),
                                                      6.25), nrow = 1) +
  annotate(geom = "text",
           label = "Congruent Plots",
           x = 0.5,
           y = 0.07)

examples_incongruent <- ggarrange(plot_example_function(data_with_resid,
                                                        "Inverted Orientation Size\nTypical Orientation Opacity",
                                                        (1-slopes$slope_inverted),
                                                        (1-slopes$slope_0.25),
                                                        6.25),
                                  plot_example_function(data_with_resid,
                                                        "Typical Orientation Size\nInverted Orientation Opacity",
                                                        (1-slopes$slope_inverted),
                                                        (1-slopes$slope_inverted),
                                                        6.25), nrow = 1) +
    annotate(geom = "text",
           label = "Incongruent Plots",
           x = 0.5,
           y = 0.07)

ggarrange(examples_congruent, examples_incongruent, nrow = 1)
```

## Point Visibility Testing {#point-visibility-testing-e4}

```{r}
#| label: visibility-e4

VT <- E4_interactions_tidy %>%
  summarise(mean_VT_no_correct = mean(VT_no_correct),
            sd_VT_no_correct = sd(VT_no_correct),
            mean_VT_perc_correct = mean(VT_perc_correct),
            sd_VT_perc_correct = sd(VT_perc_correct))
```

Discussions about the opacities and sizes of stimuli are difficult in the 
context of online, crowdsourced experiments. Unfortunately, it is not possible
to exert much control over the types of device participants use beyond insisting on 
laptops or desktop computers. In particular, the varying physical sizes, resolutions,
and dynamic ranges of participants' monitors can make commenting on the opacities 
and sizes of stimuli difficult. On the other hand, carrying out this kind of experimentation
produces findings that are more resilient to different viewing contexts than
traditional lab-based work. It is key that the manipulations employed here do not
remove data; this includes removing data by rendering it invisible. As in
\chap{chap:adjusting_size}, point visibility testing is included to address these
concerns. Participants were shown scatterplots containing between 2 and 7
points; these points were the same size and opacity as the smallest and least
opaque points used in the experimental stimuli. Participants were instructed
to enter the number of points present for each plot in a textbox. Participants
scored an average of `r printnum(VT$mean_VT_perc_correct)`% ($SD$ =
`r printnum(VT$sd_VT_perc_correct)`%). Despite the use of the opacity floor
and point size constant and scaling factor, some of the smallest, least opaque
stimuli used were clearly not visible to participants. This was most likely
due to low contrast between the foreground (scatterplot points) and the background,
as experiment 4, \chap{chap:adjusting_size} found visibility mostly invariant
to point size. In an idealised experimental setup, minimum point opacity and size
would need to calibrated on a per-monitor basis. Analysis including participants'
performance on the point visibility task as a fixed effect is detailed in 
Section \ref{results-e4}.

## Dot Pitch

```{r}
#| label: dot-pitch-e4

dot_pitch <- E4_interactions_tidy %>%
  summarise(mean_dp = mean(dot_pitch),
            sd_dp = sd(dot_pitch),
            mean_width = median(width),
            mean_height = median(height))
```

As in \chap{chap:adjusting_size}, a method for inferring the dot pitch of participants'
monitors was included in this experiment \cite{screenscale}. Section \ref{dot-pitch-chap5}
details precisely how this was accomplished. Mean dot pitch was 
  `r printnum(dot_pitch$mean_dp, digits = 2)`mm ($SD$ = `r printnum(dot_pitch$sd_dp, digits = 2)`),
corresponding to a physical on-screen size of `r printnum(dot_pitch$mean_dp*13)`mm
on a 1920 $\times$ 1080 pixel monitor for the smallest points displayed on a hypothetical
`r printnum(dot_pitch$mean_width)` $\times$ `r printnum(dot_pitch$mean_height)`cm monitor.
Analysis including dot pitch as a fixed effect is provided in Section \ref{results-e4}.

## Design {#design-e4}

A fully repeated-measures, 2 $\times$ 2 factorial design was employed. Each participant
saw each combination of opacity and size decay function scatterplots for a total
of 180 experimental items. Participants viewed these experimental items, along
with 6 attention check items, in a fully randomised order. The experiment is
hosted on Pavlovia [^1].

[^1]: https://gitlab.pavlovia.org/Strain/size_and_opacity_additive_exp

## Procedure {#procedure-e4}

Participants viewed the PIS and provided consent through key presses in response to
consent statements. Participants were asked to provide their age and gender identity.
Participants completed the 5-item Subjective Graph Literacy test \cite{garcia_2016},
followed by the screen scale and point visibility tasks described in Section \ref{method-e4}.
Following the completion of the pre-experimental tests, participants were briefly
shown examples of scatterplots with correlations of 0.2, 0.5, 0.8, and 0.95. Section
\ref{results-e4} contains a discussion of the potential effects of this training.
Two practice trials were allowed before the experiment began. Participants worked
through a series of 180 experimental and 6 attention check trials in a fully randomised
order while being asked to use a slider (see Figure \ref{fig-slider}, \chap{chap:gen_methods})
to estimate the correlation to two decimal places. Visual masks preceded
each trial. The attention check trials explicitly asked participants to set the
slider to 0 or 1.

## Participants {#participants-e4}

150 participants were recruited using the Prolific platform \cite{prolific}.
Normal or corrected-to-normal vision and English fluency were required. Participants who
had completed any of the experiments described in \chap{chap:adjusting_opacity} or \chap{chap:adjusting_size}
were prevented from participating. Data were collected from 158 participants.
8 failed more than 2 out of 6 attention check questions,
and, as per the pre-registration, had their submissions rejected from the study.
The data from the remaining 150 participants were included in the full analysis
(`r printnum(E4_interactions_tidy_gender$M, digits = 0)` male, `r printnum(E4_interactions_tidy_gender$F)`
female, and `r printnum(E4_interactions_tidy_gender$NB)` non-binary). 
Participants' mean age was `r printnum(E4_interactions_tidy_age$mean)`
(*SD* = `r printnum(E4_interactions_tidy_age$sd)`). Mean graph literacy score
was `r printnum(E4_interactions_tidy_graph_literacy$mean)` (*SD* =
`r printnum(E4_interactions_tidy_graph_literacy$sd)`). The average
time taken to complete the experiment was 37 minutes (SD = 12.3 minutes). 

# Results {#results-e4}

```{r}
#| label: model-e4
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e4_model <- buildmer(difference ~ size * opacity + 
                       (1 + size * opacity | participant) +
                       (1 + size * opacity | item),
                     data = E4_interactions_tidy)
```

```{r}
#| label: model-e4-lit-dot-pitch
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

# build additional models (literacy, dot pitch, and training)

e4_lit_model <- add_fixed_effect(e4_model, "literacy", "E4_interactions_tidy")

e4_dot_pitch_model <- add_fixed_effect(e4_model, "dot_pitch", "E4_interactions_tidy")

e4_VT_model <- add_fixed_effect(e4_model, "VT_no_correct", "E4_interactions_tidy")

e4_training_model <- add_fixed_effect(e4_model, "half", "E4_interactions_tidy")

e4_trial_number_model <- add_fixed_effect(e4_model, "trials.thisN", "E4_interactions_tidy")
```

```{r}
#| label: model-e4-cmpr
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e4_model_cmpr <- comparison(e4_model)
```

```{r}
#| label: anova-results-e4

# do all anovas now

anova_results(e4_model, e4_model_cmpr)

anova_results(e4_lit_model, e4_model)

anova_results(e4_dot_pitch_model, e4_model)

anova_results(e4_VT_model, e4_model)

anova_results(e4_training_model, e4_model)

anova_results(e4_trial_number_model, e4_model)
```

To investigate the effects of combining point opacity and size decay functions on
participants' estimates of correlation, a linear mixed effects model was built
whereby the particular combination of point opacity and size decay function
employed is a predictor for the difference between objective *r* values
for each plot and participants' estimates of *r*. Deviation coding was used
for each of the experimental factors, which allows comparison between means of
*r* estimation error and the grand mean. This model has random intercepts for 
items and participants, and random slopes for participants with regards to the
size decay factor. A likelihood ratio test revealed that the model including
the opacity and size decay conditions as predictors explained significantly
more variance than the null ($\chi^2$(`r in_paren(e4_model.df)`) = 
`r printnum(e4_model.Chisq)`, *p* `r printp(e4_model.p, add_equals = TRUE)`).
There were significant fixed effects of opacity and size decay function, as 
well as a significant interaction between the two. @fig-e4-estimates shows 
the mean errors in correlation estimation for each combination of conditions,
along with 95% confidence intervals.

```{r}
#| label: fig-e4-estimates
#| include: true
#| fig-cap: Estimated marginal means for the four conditions tested in experiment 4. 95\% confidence intervals are shown. The vertical dashed line represents no estimation error.
#| fig-asp: 0.4

# assign buildmer model to lmer slot

if (class(e4_model) == "buildmer") e4_model <- e4_model@model

as_tibble(emmeans(e4_model, pairwise ~ size * opacity)[[1]]) %>%
  mutate("size" = recode(size,
                         "S" = "Typical Orientation Size",
                         "I" = "Inverted Orientation Size"),
          "opacity" = recode(opacity,
                         "S" = "Typical Orientation Opacity",
                         "I" = "Inverted Orientation Opacity")) %>%
  ggplot(aes(x = reorder(size:opacity, emmean), y = emmean*-1)) +
  geom_point(size = 1.75) +
  geom_pointrange(aes(ymin = asymp.LCL*-1, ymax = asymp.UCL*-1)) +
  scale_x_discrete(labels = ~ gsub(":", "\n", .x)) +
  theme_ggdist() + 
  labs(y = "Estimated Marginal Mean of Error",
       x = " Size : Opacity") +
  theme(axis.text = element_text(size = 7),
        axis.title = element_text(size = 8)) +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
  coord_flip() +
  geom_abline(intercept = 0, slope = 0, linetype = 2) +
  annotate(geom = "segment",
                   x = 4.4,
                   xend = 4.4,
                   y = -.02,
                   yend = -.08,
           arrow = arrow(type = "closed", length = unit(0.1, "cm" ))) +
  annotate(geom = "segment",
                   x = 4.4,
                   xend = 4.4,
                   y = .02,
                   yend = .08,
           arrow = arrow(type = "closed", length = unit(0.1, "cm"))) +
  annotate(geom = "text",
           x = 4.15,
           y = -.05,
           label = "Underestimation",
           size = 3) +
  annotate(geom = "text",
           x = 4.15,
           y = .05,
           label = "Overestimation",
           size = 3) +
  annotate(geom = "text",
           x = 2.5,
           y = 0.008,
           label = "No Estimation Error",
           size = 2.5,
           angle = 270)
```

```{r}
#| label: tbl-contrasts-e4
#| include: true
#| tbl-cap: Contrasts between different levels of the opacity and size decay factors in experiment 4.

# assign slot, if it hasn't been assigned already

if (class(e4_model) == "buildmer") e4_model <- e4_model@model

# make table df

contrasts_extract(e4_model, "size:opacity") %>%
  mutate('Contrast' = recode(Contrast,
         "S I - I I" = "TO Size x IO Opacity | IO Size x IO Opacity",
         "S I - S S" = "TO Size x IO Opacity | TO Size x TO Opacity",
         "S I - I S" = "TO Size x IO Opacity | IO Size x TO Opacity",
         "I I - S S" = "IO Size x IO Opacity | TO Size x TO Opacity",
         "I I - I S" = "IO Size x IO Opacity | IO Size x TO Opacity",
         "S S - I S" = "TO Size x TO Opacity | IO Size x TO Opacity")) %>%
  mutate(Contrast = str_replace(Contrast, " - ", " | ")) %>%
  separate(Contrast, into = c(" ", "  "), sep = " \\| ") %>%
  kbl(booktabs = TRUE, digits = c(0,2,3), escape = FALSE) %>%
  add_header_above(c("Contrast" = 2, "Statistics" = 2))
```

The effects found were driven by significant difference between means of correlation
estimation error between all conditions besides that which compares the two
incongruent decay conditions. Statistical testing for contrasts were performed
using the `emmeans` package \cite{lenth_2024}, and are provided in @tbl-contrasts-e4.
Experiments 1, 2, and 3 all featured identical comparative baseline conditions. In the former
two experiments, this was the full contrast condition (see \chap{chap:adjusting_opacity}),
while in the latter, this was the standard size condition (see \chap{chap:adjusting_size}).
In the current experiment, no baseline condition was used. Owing both to this
and the use of a linear mixed effects model with an interaction term, the use of
Cohen's *d* as a measure of effect size would be inappropriate. In its place,
the amounts of variance in participants' errors in correlation estimation
explained by each fixed effect term and the interaction term is represented as 
semi-partial R^2^ \cite{nakagawa_2013}. These statistics were calculated using
the `r2glmm` package (version 0.1.2) \cite{r2glmm}, and are presented along with model statistics
in @tbl-model-stats-e4.

```{r}
#| label: tbl-model-stats-e4
#| include: true
#| tbl-cap: Significances of fixed effects and the interaction between them. Semi-partial R^2^ for each fixed effect and the interaction term is also displayed in lieu of effect sizes.

make_sig_table(e4_model)
```

```{r}
#| label: fig-e4-trial-number
#| include: true
#| fig-cap: Comparing mean errors in correlation estimation by trial number. Points represent unsigned mean errors for each trial number. The plotted line is the locally estimated smoothed curve, with the ribbon representing standard errors.
#| fig-asp: 0.4

E4_interactions_tidy %>%
  drop_na() %>%
  group_by(trials.thisN) %>%
  summarise(sd = sd(abs(difference)), mean = mean(abs(difference))) %>%
  ggplot(aes(x = trials.thisN, y = mean)) +
  geom_point(alpha = 0.4, shape = 16) +
  geom_smooth(se = T, span = 0.5, colour = "black", size = 0.7,) +
  scale_x_continuous(breaks = seq(0,180, by = 20), limits = c(0, 180)) +
  geom_vline(xintercept = 0, linetype = 2) +
  geom_vline(xintercept = 90, linetype = 2) +
  geom_vline(xintercept = 180, linetype = 2) +
  labs(x = "Trial Number",
       y = "Unsigned Mean Error") +
  annotate("text",
           x = 45,
           y = 0.145,
           label = "1st Half") +
    annotate("text",
           x = 135,
           y = 0.145,
           label = "2nd Half") +
  theme_ggdist() +
  theme(axis.text = element_text(size = 7),
        axis.title = element_text(size = 8)) 
```

Models including participants' graph literacy, their performance on the
point visibility task, the dot pitch of participants' monitors, and which 
half of the experiment a particular correlation judgement took place were built
and compared with the experimental model. While no significant effects of
graph literacy ($\chi^2$(`r in_paren(e4_lit_model.df)`) = `r printnum(e4_lit_model.Chisq)`, *p* `r printp(e4_lit_model.p, add_equals = TRUE)`),performance on the point visibility 
task ($\chi^2$(`r in_paren(e4_VT_model.df)`) = `r printnum(e4_VT_model.Chisq)`,
*p* `r printp(e4_VT_model.p, add_equals = TRUE)`), or  dot pitch 
($\chi^2$(`r in_paren(e4_dot_pitch_model.df)`) = `r printnum(e4_dot_pitch_model.Chisq)`,
*p* `r printp(e4_dot_pitch_model.p, add_equals = TRUE)`) were found, there was a 
significant effect of training ($\chi^2$(`r in_paren(e4_training_model.df)`) = 
`r printnum(e4_training_model.Chisq)`, *p* `r printp(e4_training_model.p, add_equals = TRUE)`),
with participants rating correlation .01 lower during the second half. This drop
suggests that having more recently viewed the training plots may have increased
participants' estimates of correlation. To further analyse this variability,
a model was built including trial number, allowing for the analysis of error purely
as a function of when an experimental trial took place.
A significant effect of trial number is also found ($\chi^2$(`r in_paren(e4_trial_number_model.df)`) = 
`r printnum(e4_trial_number_model.Chisq)`, *p* `r printp(e4_trial_number_model.p, add_equals = TRUE)`)
on participants' correlation estimation errors. @fig-e4-trial-number shows
participants' unsigned mean errors in correlation estimation against trial 
number. Variability in error, as represented by the ribbon, stabilised quickly 
and remained stable for most the experiment, only widening again around 
trial number 170. The simplest explanation for this is that participants,
knowing they were coming to the end of the experiment, became less vigilant 
and rushed their judgements more. Regardless of statistical significance, 
this effect is not large enough to warrant further investigation,
at least as it pertains to correlation estimation in scatterplots.

# Discussion {#discussion-e4}

```{r}
#| label: fig-estimates-by-r-e4
#| include: true
#| fig-cap: Participants' mean errors in correlation estimates grouped by factor and by \textit{r} value. The dashed horizontal line represents perfect estimation. Participants were most accurate when presented with the plots in the congruent, typical orientation condition. Error bars show standard deviations of estimates.

plot_error_bars_function(E4_interactions_tidy %>%
                           mutate(grouping_var = fct_relevel(condition_abs,
                                                             c("A",
                                                               "B",
                                                               "X",
                                                               "Y"))),
                         "condition_abs",
                         "difference",
                         labels_e4) +
  geom_hline(yintercept = 0, linetype = 2)
```

Hypothesis 1 received full support in this experiment. The combination of 
typical orientation opacity and size decay functions produced the most accurate
estimates of correlation, although this also resulted in a marked over-correction
and consequent overestimation for many values of *r* (see @fig-estimates-by-r-e4).
The second hypothesis also received support; the combination of inverted opacity
and size decay functions produced the least accurate estimates of correlation.
No support was found for the third hypothesis, that there would be a significant
difference in correlation estimates between inverted orientation opacity/typical
orientation size plots and typical orientation opacity/inverted orientation
size plots. There was, however, a significant interaction term present,
providing evidence that the combination of opacity and size decay functions is
not additive in nature.

Further confirmatory evidence is found in favour of the phenomena reported in
\chap{chap:adjusting_opacity} and \chap{chap:adjusting_size}. Namely, that while
manipulations of both point opacity and size in scatterplots have significant
effects on correlation estimation, the effect of changing point size is stronger,
and that while manipulations such as those described in this thesis can influence
estimates of positive correlation in either direction, typical orientation 
manipulations are more powerful than inverted ones. As expected, there is also
an effect of congruency on the extent to which a manipulation can bias estimates of
correlation; redundant encoding, such as that present here in congruent conditions,
is known to support visual grouping and segmentation \cite{nothelfer_2017}. The 
findings presented here provide evidence that redundancy can be exploited to
change perceptions of correlation.

Given the consistent finding throughout this thesis that point size is a stronger
encoding channel for the purposes of altering perceptions of correlation compared 
to point opacity, the lack of support for the third hypothesis was unexpected.
Tentatively, this may be a result of the non-additive nature of combining
point opacity and size manipulations. Despite this, it was found that point size
explained a greater proportion of the variance (.104) in the experimental model
compared to point opacity.

Taking into account the work presented in this chapter, along with that described
in \chap{chap:adjusting_opacity} and \chap{chap:adjusting_size}, recommendations 
can be made for designers of correlation visualisations:

 - When *r* is between approximately 0.3 and 0.75, and the scatterplot in question
 is intended solely for the communication of correlation, designers may wish to
 implement the non-linear size decay function, as findings 
 have shown it to produce the most accurate correlation estimates in this range.
 - Outside of this range, and with the same caveats in place, designers may wish
 to implement the opacity decay function described in \chap{chap:adjusting_opacity};
 while its effect on correlation estimation
 is small, it does significantly increase estimation accuracy.
 - There exists a combination of size and opacity decay functions that produces
 accurate correlation estimates while maintaining the increased *r* estimation
 precision expected with high *r* values. Finding this will require extensive future testing.

## Combining Manipulations

@fig-e4-estimates and @fig-estimates-by-r-e4 show how, on average, the combination
of typical orientation opacity and size decay functions results in an overestimation
of *r* for the majority of values. While not solving the underestimation problem
directly, it demonstrates that with regards to using point opacity and size manipulations
to change estimates of correlation, there appear to be few limitations. If correlation
estimation can be over-corrected, as in the typical orientation condition here,
then there exists a *tuning* of the opacity and size decay parameters such
that the degree of correction is appropriate; Section \ref{future-work-e4} explores
the work that might be done to achieve this. The combination of inverted
orientation opacity and size decay functions also had the expected effect, producing
the lowest and least accurate estimates of correlation. Combining inverted
manipulations did not, however, significantly change the shape of the estimation
curve (see @fig-estimates-by-r-e4). In addition to non-additive interaction, the
effects observed operate differently depending on the direction of the change
induced in perception. This finding may also explain the lack of support for
the third hypothesis, that there would be a significant difference in estimation
error between the two incongruent conditions. Despite the size channel being
more powerful than opacity with regards to influencing correlation estimates,
the fact that this power depends on the direction the function is set causes
incongruent decay conditions to act against each other in unexpected ways.
Indeed, the incongruent condition that used a typical orientation size decay function exhibited
lower mean error than the one using inverted orientation size decay (see @fig-estimates-by-r-e4),
however in each case opacity decay appears to have blunted the power of the
size decay function to the extent that the difference in errors is not statistically
significant.

## Estimation Precision

Previous work has been consistent regarding the finding that *r* estimation precision
increases with the objective *r* value displayed in the scatterplot 
\cite{doherty_2007, rensink_2012, rensink_2014, rensink_2017}. The experiments
carried out in \chap{chap:adjusting_opacity} and \chap{chap:adjusting_size} found
that in some cases, precision in *r* estimation is constant across the range of 
*r* values investigated. For example, the use of a size decay function, whether
linear or non-linear decay in typical or inverted directions, results in no
change in *r* estimation precision (see Section \ref{results-e3}, \chap{chap:adjusting_size}).
When point opacity was altered in the same way, only an inverted decay function does not exhibit
the conventional increase in *r* estimation precision with increasing objective *r* value.
In the experiment described presently, precision in *r* estimation increased
whenever a typical orientation opacity decay function was used. This may be
part of the moderating effect of point opacity decay on the size decay function;
the visual character of scatterplots with high *r* values that use the size decay
function eliminates the usual increase in precision one would expect,
however the introduction of the opacity decay function normalises
this to the point where precision is restored.

## Relative Contributions of Opacity and Size Decay

```{r}
#| label: fig-all-est-curves
#| include: true
#| fig-cap: Plotting errors in *r* estimation against objective *r* values for opacity and size decay functions. On the left, opacity and size decay functions in combination in the typical orientation congruent condition from the current experiment. The plots in the centre show estimation error for opacity and size decay functions in isolation from previous chapters. The right-hand plot averages the comparitive baseline (standard scatterplotr) conditions from the previous two chapters.

# set facet orders

facet_order <- c("opacity_manipulated", "size_manipulated", "additive_manipulation", "standard_plot")

standard_alone <- read_csv("../data/exp_1_to_4_combined.csv") %>%
    drop_na() %>%
    filter(factor == "standard_plot") %>%
    group_by(factor, my_rs) %>% 
    summarise(sd = sd(difference), mean = mean(difference)) %>%
    arrange(my_rs) %>%
    mutate(group = ceiling(row_number() / 2)) %>%
    group_by(group) %>%
    summarise(
      factor = first(factor),
      my_rs = mean(my_rs),
      sd = mean(sd),
      mean = mean(mean)
    ) %>%
  ungroup() %>%
  select(-group)

all_exp_df <- read_csv("../data/exp_1_to_4_combined.csv") %>%
    drop_na() %>%
    filter(factor != "standard_plot") %>%
    group_by(factor, my_rs) %>% 
    summarise(sd = sd(difference), mean = mean(difference)) %>%
    mutate(factor = factor(factor, levels = facet_order))

plotting_df <- rbind(all_exp_df, standard_alone)

  plotting_df %>% 
    ggplot(aes(x = my_rs, y = -1*mean)) + 
    geom_errorbar(mapping = aes(ymin = -1*mean + sd, ymax = -1*mean - sd),width = 0.01, size = 0.3) +
    theme_ggdist() +
    scale_y_continuous(breaks = seq(-0.4,1, 0.2)) +
    theme(strip.text = element_text(size = 6, margin = margin(1,0,1,0, "mm")),
        axis.text = element_text(size = 7),
        axis.title.x = ggtext::element_markdown(size = 8),
        axis.title.y = ggtext::element_markdown(size = 8)) +
    facet_wrap(factor ~., ncol = 4, labeller = labeller(factor = labels_all_exp)) +
    labs(x = "Objective *r*",
         y = "Mean *r* Estimation Error") +
    geom_smooth(se = FALSE, colour = "black", size = 0.4) +
    xlim(0.2,1) + 
    geom_hline(yintercept = 0, linetype = 2)
```

Incorporating the data gathered in \chap{chap:adjusting_opacity} and
\chap{chap:adjusting_size} allows for the comparison of estimation curves
for size decay and opacity decay both in isolation and combination. @fig-all-est-curves
shows correlation estimation error curves in the present experiment (typical orientation congruent),
and in the non-linear decay conditions for both opacity decay (\chap{chap:adjusting_opacity})
and size decay (see \chap{chap:adjusting_size}) conditions. The "no manipulations
present" plot is averaged from the results of experiments 1 to 3. Using
opacity decay alone significantly changes the amplitude of the estimation curve,
while leaving its shape intact; this can be seen by comparing opacity decay
and standard scatterplot plots in @fig-all-est-curves. Using size decay changes
both the amplitude and the shape of the estimation curve. When opacity and size
decay functions are combined, the shape of the curve is most similar to that
observed when size decay is employed in isolation. This is in line with findings,
both here and in previous work \cite{hong_2022}, that size is a more potent
encoding channel for the manipulation of perceptual estimates derived from
scatterplots. It would appear then that the addition of the opacity curve moderates the effect of size decay
as a function of the objective *r* value itself, without affecting the general
shape of the curve.

Using an opacity decay function in isolation has a small effect on correlation
estimation. It does little to change the shape of the underestimation curve, but 
rather slightly biases *r* estimates upwards to partially correct for the 
underestimation observed with standard scatterplots. Importantly, it also
preserves the increase in correlation estimation precision with *r* expected.
Using the size decay function in isolation has a more dramatic effect. Size decay
over-corrects at lower *r* values, leading to an overestimation effect;
at higher values, underestimation still occurs. At mid-range values of 
*r*, however, the size decay function performs significantly better than all others.
One option for tuning correlation estimation using the decay functions described in 
this thesis would therefore be to use size decay in isolation for mid-range
*r* values (around 0.3 to 0.75), and to use opacity decay in isolation outside
of this range. Combining the decay functions, however, allows for the exploitation
of the power of the size decay function while maintaining the expected increase
in *r* estimation precision that the opacity decay function confers. The simple
combination used in the present experiment does not represent an ideal tuning,
as participants overestimated *r* for the majority of values; the findings here
do, however, confirm that there is the scope to bias *r* estimation to greater degrees
compared to scatterplots that use point opacity or size decay functions in
isolation. Precise values for the contributions of each encoding channel
when they are used simultaneously would be needed to begin doing this work.
To describe the effect that each decay function (and their combination) has
on correlation estimates, new curves can be derived that compare estimates made
with opacity and size decay to those made without.

```{r}
#| label: fig-power-plot-e4
#| include: true
#| fig-cap: Power is the difference between what is observed when a decay function/combination of decay functions is used and what is observed when no manipulation is used. The dashed line represents the power that would be required to correct for the observed underestimation of correlation in scatterplots. The integral of each power curve over \textit{r} is provided, as well as the difference between this integral and the integral of each required-power curve over \textit{r}.

# dataframe containing values from previous experiments and the current is included
# in the data folder 

curves <- read_csv("../data/curves_df.csv") 

facet_order <- c("opacity_power", "size_power", "additive_power")

# create necessary power curve

necessary_power <- curves %>% select(c("my_rs", "standard_curve")) %>%
  mutate(mirror = my_rs-standard_curve)

# find integrals

int_df <- left_join(curves, necessary_power, by = "my_rs")

area_opac <- round(AUC(int_df$my_rs, int_df$opacity_power) - AUC(int_df$my_rs, int_df$mirror), 3)

area_size <- round(AUC(int_df$my_rs, int_df$size_power) - AUC(int_df$my_rs, int_df$mirror), 3)

area_combined <- round(AUC(int_df$my_rs, int_df$additive_power) - AUC(int_df$my_rs, int_df$mirror), 3)

int_opac <- round(AUC(int_df$my_rs, int_df$opacity_power), 3)

int_size <- round(AUC(int_df$my_rs, int_df$size_power), 3)

int_combined <- round(AUC(int_df$my_rs, int_df$additive_power), 3)

# create area and int labels for facetted plots

area_labels <- tibble(
  label = c(substitute(expression(integral(italic(f)(italic(x)) - italic(g)(italic(x))*italic(dx), 0.2, 1) == a), list(a = area_opac)),
            substitute(expression(integral(italic(f)(italic(x)) - italic(g)(italic(x))*italic(dx), 0.2, 1) == a), list(a = area_size)),
            substitute(expression(integral(italic(f)(italic(x)) - italic(g)(italic(x))*italic(dx), 0.2, 1) == a), list(a = area_combined))),
  factor = c("opacity_power", "size_power", "additive_power"),
)

int_labels <- tibble(
  label = c(substitute(expression(integral(italic(f)(italic(x))*italic(dx), 0.2, 1) == a), list(a = int_opac)),
            substitute(expression(integral(italic(f)(italic(x))*italic(dx), 0.2, 1) == a), list(a = int_size)),
            substitute(expression(integral(italic(f)(italic(x))*italic(dx), 0.2, 1) == a), list(a = int_combined))),
  factor = c("opacity_power", "size_power", "additive_power"),
)

# create plot

 curves %>% 
    drop_na() %>%
    select(c("opacity_power",
             "size_power",
             "additive_power",
             "my_rs")) %>%
    pivot_longer(cols = c("opacity_power",
                          "size_power",
                          "additive_power"),
                 names_to = "factor", values_to = "power") %>%
    mutate(factor = factor(factor, levels = facet_order)) %>%
    group_by(factor, my_rs) %>% 
    summarise(sd = sd(power), mean = mean(power)) %>% 
    ggplot(aes(x = my_rs, y = mean)) + 
    theme_ggdist() +
    scale_y_continuous(breaks = seq(-0.4,1, 0.2)) +
    theme(strip.text = element_text(size = 6, margin = margin(1,0,1,0, "mm")), aspect.ratio = 1,
          axis.text = element_text(size = 7),
          axis.title.x = ggtext::element_markdown(size = 8),
          axis.title.y = ggtext::element_markdown(size = 8)) +
    facet_wrap(factor ~., ncol = 5, labeller = labeller(factor = labels_power)) +
    labs(x = "Objective *r*",
         y = "Power") +
    geom_smooth(se = FALSE, colour = "black", size = 0.4) +
    geom_smooth(data = necessary_power,
                aes(x = my_rs, y = mirror),
                se = F,
                linetype = 3,
                colour = "black",
                size = 0.4) +
    xlim(0.2,1) +
    ylim(-0.1,0.3) +
    geom_text(data = area_labels,
              parse = T,
              mapping = aes(x = -Inf, y = -Inf, label = gsub("^.(.*).$", "\\1", str_replace(label, "expression", ""))),
              hjust = -0.4,
              vjust = -0.2,
              size = 2.5) +
       geom_text(data = int_labels,
              parse = T,
              mapping = aes(x = -Inf, y = -Inf, label = gsub("^.(.*).$", "\\1", str_replace(label, "expression", ""))),
              hjust = -0.6,
              vjust = -1.4,
              size = 2.5)

```

This contribution is termed *power*, and is visualised in @fig-power-plot-e4. As can
be seen in the right-hand plot, size decay in isolation provides the closest to the 
required level of correction, and combining point opacity and size decay results
in gross overestimation. @fig-power-plot-e4 also includes the integral of each
power curve over *r* as a measure of the total power of each curve. Subtracting the
integral of the required power curve from the integral of the observed power
curve allows a numerical value to be calculated for how far off each manipulation is.

## Mechanisms

Findings in \chap{chap:adjusting_opacity} and \chap{chap:adjusting_size} made the
case for opacity and size decay acting primarily through point salience and 
perceptual weighting, with the caveat that spatial certainty also plays a small
part in the mechanism behind the effects of point size decay. The results in the
present experiment are supportive of this notion, with the highest and lowest 
mean estimates being observed in the congruent typical and congruent inverted
orientation conditions respectively. These findings also support dot density \cite{yang_2023}
and featured-based attention bias accounts \cite{hong_2022, sun_2016}. As all
these mechanisms would produce similar results, making conclusions about the
relative potential contributions of each is difficult. Nevertheless, on a higher
level, the evidence generally points towards a probability distribution accounts
\cite{rensink_2017, rensink_2022}. On a lower level, however, numerous candidate
mechanisms exist. The results from the current experiment provide further
evidence for a point salience/perceptual weighting account. Hong et al. \cite{hong_2022}
found that the inclusion of larger and more opaque scatterplot points was able
to bias estimates of positional means, but that the relative contributions
(weights) of these visual features with regards to perception change as a function
of the ranges of opacities and sizes used. It is clear from this evidence
and the present that the perceptual weightings of opacity and size are not the same.

## Limitations {#limitations-e4}

First, participants' performance on the point visibility task. This was poor,
with an average of only `r printnum(VT$mean_VT_perc_correct)`%. It would seem that
despite the implementation of the opacity floor and the size scaling factor
and constant, many stimuli were simply not visible. While modelling indicates
that this did not have a significant effect on errors of correlation estimation,
for many participants it will have seemed as if data had been removed, violating
the intended aims of the manipulations. Addressing this properly would require a
by-participant calibration of the necessary minimum point opacity and size
values to ensure visibility, as these values will change as a function of head-to-monitor
distance and monitor characteristics.

While evidence has been found that combining point opacity and size decay 
is not additive, it is difficult to comment precisely on what proportions
of the observed effects are a result of each manipulation. Previous work \cite{hong_2022},
as well as the work carried out here and in \chap{chap:adjusting_size},
suggest that point size has much more potential to change perceptual estimates,
although the exact ways in which of opacity and size manipulations would require
future work.

Due to the extensive testing of "no manipulations present" conditions (*full opacity*
in \chap{chap:adjusting_opacity} and *standard size* in \chap{chap:adjusting_size}),
a comparative baseline was not included in this work. At the time it was judged
that the increased cost and experimental length was not worth the inclusion of 
further conditions beyond the four that were tested.

Channels such as point size, colour, opacity, and shape have been used in past
work to encode variables beyond the standard two typically used in scatterplots
\cite{smart_2019, hong_2022}. While this work focuses purely on correlation estimation,
these techniques are likely to lead to incorrect interpretations when scatterplots
are designed with other tasks in mind. Given evidence that size, shape, and colour
are not entirely separable scatterplot features \cite{smart_2019}, if viewers
assume that variations in point opacity/size correspond to additional
encoded variables, confounds in interpretation may be introduced. If plots such
as the ones presented here were to appear in the wild, however, it would be
necessary to clarify that they were designed to aid in the
rapid and intuitive interpretation of correlation (and *only* this). Irrespective
of the potential for misinterpretation, strong baseline evidence for 
a perceptual effect of changing point size and opacity in scatterplots is provided that may
be expanded on and further exploited in future work.

## Future Work {#future-work-e4}

The finding that combining point opacity and size manipulations significantly
reduced point visibility suggests the potential for future work investigating
the calibration of scatterplot visual features for a particular participant. Doing
this would require a more dynamic experimental environment in which stimuli
could be regenerated on-the-fly, but would allow researchers to test perceptions
more accurately. 

Experimental limitations meant that this work did not feature a comparative 
baseline condition, unlike in \chap{chap:adjusting_opacity} and \chap{chap:adjusting_size}.
Future work may wish to re-test all or some of the conditions described here in
addition to a baseline, no manipulations condition.

There is evidence that viewers overestimate correlation in negatively correlated
scatterplots \cite{sher_2017}. Findings that correlation perception in negatively
correlated scatterplots functions symmetrically to that of positively correlated
scatterplots \cite{harrison_2014} suggest that the techniques implemented here
may be used (in a symmetrical manner) to address the overestimation bias.
Evidence that the influence of size and opacity decay functions changes according to the direction
they are operating in means experimental work with negatively correlated
scatterplots would be required, and results may differ significantly from
findings related to the underestimation of correlation in positively
correlated scatterplots.

All the work in the present chapter, along with that in \chap{chap:adjusting_opacity}
and \chap{chap:adjusting_size}, uses the same equation (reproduced below) to relate point residuals
to specific opacity and size values.

\begin{equation}
  point_{size/opacity} = 1 - b^{residual}
\end{equation}

Given the finding that the combination of point opacity and size decay is not additive,
there are a multitude of parameters that may be adjusted and tested to explore
the relative contributions of each to the effects seen. The value of *b*, which
so far has only been b = 0.25, is one such parameter, and controls the severity
of the fall-off in point opacity or size of the decay function in question. The opacity floor, size scaling
factor, and size constant are other values that might be changed. Of course,
the equation used is not exhaustive; future work may wish to investigate more
complicated equations that link the objective *r* value to the decay condition.

Future experimental work may use the major axis through the probability ellipse
instead of the regression line as a baseline to change point sizes and opacities;
evidence that people often report the major axis when asked to visually estimate
the regression line \cite{collyer_1990} suggests that this may produce a
different pattern of results from those seen here. If changes in dot density are
driving changes in correlation estimates, the congruent
conditions here are an example of redundant encoding. Future work may explore using different
channels to redundantly encode dot density, such as marker shape, orientation, or colour.
Further testing of opacity and size manipulations in isolation and combination using
different decay function parameters will allow researchers to build a more complete
picture of how these visual features impact correlation estimation, and how we
can exploit them to correct for well-known biases.

Finally, while point salience/perceptual weighting is put forward as the most likely
driver of the effects observed, the data gathered here do not explain the
differences in the shapes of the observed correlation estimation curves (see @fig-all-est-curves).
The context that a particular point manipulation is presented in, including the
objective *r* value of the scatterplot, interacts with point opacity and size
adjustments in complex ways. Future work may wish to use the same decay conditions
while fixing the objective *r* value to explore these interactions in greater detail.

# Conclusion {#conclusion-interactions}

In a single experiment that combined the point opacity manipulation from 
\chap{chap:adjusting_opacity} and the point size manipulation from \chap{chap:adjusting_size},
evidence is provided that this combination is not additive in nature. In addition
to opening up questions about the complexity of this interaction, this work
shows that there is scope to bias correlation estimates significantly; the finding
that the combination of non-linear opacity and size decay functions produces
marked overestimation emphasises this. Exploring exactly how these decay functions
interact with a view to tuning correlation perception is beyond the scope of this
thesis; the foundation has, however, been laid.


