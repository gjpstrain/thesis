---
title: "general_methodology"
output:
  format: 
    latex:
params:
  eval_models: false
  
knitr:
  opts_chunk: 
    cache_comments: false
    crop: true
    
execute: 
  echo: false
  warning: false
  message: false
  include: false     
---

# Introduction

In this chapter we describe our research methodologies. Chapters 4, 5, and 6 share
most aspects of experimental method, while the experiment described in chapter 7 differs
substantially. Throughout this chapter, the reader should assume that we are 
referring to the entire body of experimental work this thesis describes. Methods
that differ regarding the final experiment in chapter 7 are detailed along the way.
In this chapter, we discuss our experimental designs, the tools we use to build
and run our experiments, our approach to statistical analyses, and the computational
methods and practices we employed particularly with regards to reproducibility
and open science.

# Experimental Methods

It is important to acknowledge that the way in which we conduct experiments influences
what we find and the conclusions that we may draw from those findings. The decisions
that lead us to designing experiments in certain ways must be based not only
on theory, but also on the practical constraints imposed by external factors on
the research team. Concerns such as time, convenience, and cost must be addressed,
and a compromise between research that is *valuable* and research that is *doable*
must be reached. We focused on pragmatism and impact throughout the course of this
research project; happily, the research journey we embarked on resulted in methodologies
that satisfied both principles. It is for this reason that we consider the framework
we present to be a key contribution of this thesis.

## Experimental Design

All but our final experiment utilised within-participants designs. Each
participant saw all experimental stimuli and provided a judgement 
of correlation using a sliding scale between 0 and 1 (see @fig-slider). Experiments 1 to 3 featured
featured a single experimental factor of design, all with 4 levels corresponding
to scatterplots with different design features. Experiment 4 employed a factorial
2 $\times$ 2 design. Experiment 5 is a departure from the shared experimental
paradigm of the previous experiments, and features a 1 factor, 2 level 
between-participants design.

```{r}
#| label: fig-slider
#| include: true
#| fig-cap: An example of the slider participants used to estimate correlation in experiments 1-4.
#| out-width: NA
#| out-height: NA

knitr::include_graphics(path = "../supplied_graphics/example_slider.png", dpi = NA)
```

## Tools for Testing

Whatever the design of our experiments, software plays a crucial role in allowing 
us to carry them out. Fortunately, at the time of writing, there is a wealth of 
tools available to facilitate the testing of visualisations both in traditional
lab-based tests and in online experiments. As we adhere to the principles of 
open and reproducible research \cite{ayris_2018}, we discount closed-source
software, such as Gorilla \cite{anwyl_2020} or E-prime \cite{eprime_2020}, as these
rely on paid licenses and do not allow us to share code with future researchers.
We settled on using PsychoPy \cite{peirce_2019} due to its open-source status,
flexibility regarding graphical and code-based experimental design, and high 
level of timings accuracy \cite{bridges_2020}. Using such a open-source tool not only
facilitated our own learning with regard to experiment building, but also enables
to contribute further examples of visualisation studies by hosting the resulting
experiments online for use and modification by future researchers.

We elected to pursue online testing throughout this thesis. Doing so is 
much quicker than carrying out in-person lab-based testing, meaning we can collect
data from a much larger number of participants. This reduces the chances of detecting
false positives during analysis and ensures adequate levels of power despite the
potential for small effects sizes. Online testing also affords us access to 
diverse groups of participants across our populations of interest, especially
when compared to the relatively homogeneous student populations usually accessed
by doctoral researchers.

## Creating Stimuli

## Recruitment

# Analytical Methods

## Linear Mixed-Effects Models

## Advantages Over Aggregate-Level Statistical Tests

## Model Construction

## Effects Sizes

## Reporting Analyses

# Computational Methods

## Executable Reporting

## Containerised Environments

# Reproducibility In This Thesis

## Sharing Data and Code

## Executable Papers and Docker Containers

## Experimental Resources

# Conclusion
